(module
  ;; Combined Real FFT - Radix-2 and Radix-4 with automatic dispatch
  ;;
  ;; For N real inputs, uses N/2-point complex FFT internally.
  ;; Automatically selects the optimal algorithm for the internal FFT:
  ;; - Radix-4 when N/2 is power-of-4 (N=8, 32, 128, 512, 2048, 8192)
  ;; - Radix-2 Stockham otherwise (N=16, 64, 256, 1024, 4096)
  ;;
  ;; Memory layout (f64, 16 bytes per complex):
  ;;   0 - 131071:        Primary buffer (up to 8192 complex = N=16384 real)
  ;;   131072 - 262143:   Secondary buffer (Stockham ping-pong)
  ;;   262144 - 393215:   Complex FFT twiddles (for N/2-point FFT)
  ;;   393216+:           Post-processing twiddles W_N^k for k=0..N/2
  ;;
  ;; For N=16384 real FFT: 8 pages needed

  (memory (export "memory") 8)

  (global $SECONDARY_OFFSET i32 (i32.const 131072))
  (global $TWIDDLE_OFFSET i32 (i32.const 262144))
  (global $RFFT_TWIDDLE_OFFSET i32 (i32.const 393216))
  (global $PI f64 (f64.const 3.141592653589793))
  (global $HALF_PI f64 (f64.const 1.5707963267948966))

  ;; SIMD sign mask for complex multiply
  (global $SIGN_MASK v128 (v128.const i64x2 0x8000000000000000 0x0000000000000000))
  ;; Conjugate mask: flips sign of imaginary part (second lane)
  (global $CONJ_MASK v128 (v128.const i64x2 0x0000000000000000 0x8000000000000000))

  ;; ============================================================================
  ;; Utility: Check if N is a power of 4
  ;; ============================================================================
  (func $is_power_of_4 (param $n i32) (result i32)
    (i32.and
      (i32.eqz (i32.and (local.get $n) (i32.sub (local.get $n) (i32.const 1))))
      (i32.eqz (i32.and (local.get $n) (i32.const 0xAAAAAAAA))))
  )

  ;; ============================================================================
  ;; Inline Trig Functions (Taylor Series)
  ;; ============================================================================
  (func $sin (param $x f64) (result f64)
    (local $x2 f64) (local $term f64) (local $sum f64)
    (if (f64.lt (local.get $x) (f64.neg (global.get $PI)))
      (then (local.set $x (f64.add (local.get $x) (f64.mul (f64.const 2.0) (global.get $PI))))))
    (if (f64.gt (local.get $x) (global.get $PI))
      (then (local.set $x (f64.sub (local.get $x) (f64.mul (f64.const 2.0) (global.get $PI))))))
    (if (f64.gt (local.get $x) (global.get $HALF_PI))
      (then (local.set $x (f64.sub (global.get $PI) (local.get $x)))))
    (if (f64.lt (local.get $x) (f64.neg (global.get $HALF_PI)))
      (then (local.set $x (f64.sub (f64.neg (global.get $PI)) (local.get $x)))))
    (local.set $x2 (f64.mul (local.get $x) (local.get $x)))
    (local.set $sum (local.get $x))
    (local.set $term (local.get $x))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -6.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -20.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -42.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -72.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -110.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -156.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -210.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (local.get $sum)
  )

  (func $cos (param $x f64) (result f64)
    (local $x2 f64) (local $term f64) (local $sum f64) (local $sign f64)
    (if (f64.lt (local.get $x) (f64.neg (global.get $PI)))
      (then (local.set $x (f64.add (local.get $x) (f64.mul (f64.const 2.0) (global.get $PI))))))
    (if (f64.gt (local.get $x) (global.get $PI))
      (then (local.set $x (f64.sub (local.get $x) (f64.mul (f64.const 2.0) (global.get $PI))))))
    (local.set $sign (f64.const 1.0))
    (if (f64.gt (local.get $x) (global.get $HALF_PI))
      (then
        (local.set $x (f64.sub (global.get $PI) (local.get $x)))
        (local.set $sign (f64.const -1.0))))
    (if (f64.lt (local.get $x) (f64.neg (global.get $HALF_PI)))
      (then
        (local.set $x (f64.add (global.get $PI) (local.get $x)))
        (local.set $sign (f64.const -1.0))))
    (local.set $x2 (f64.mul (local.get $x) (local.get $x)))
    (local.set $sum (f64.const 1.0))
    (local.set $term (f64.const 1.0))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -2.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -12.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -30.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -56.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -90.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -132.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (local.set $term (f64.mul (local.get $term) (f64.div (local.get $x2) (f64.const -182.0))))
    (local.set $sum (f64.add (local.get $sum) (local.get $term)))
    (f64.mul (local.get $sum) (local.get $sign))
  )

  ;; ============================================================================
  ;; Twiddle Precomputation (for complex FFT)
  ;; ============================================================================
  (func $precompute_twiddles (param $n i32)
    (local $k i32) (local $angle f64) (local $addr i32) (local $neg_two_pi_over_n f64)
    (if (i32.le_u (local.get $n) (i32.const 4)) (then (return)))
    (local.set $neg_two_pi_over_n
      (f64.div (f64.mul (f64.const -2.0) (global.get $PI)) (f64.convert_i32_u (local.get $n))))
    (local.set $addr (global.get $TWIDDLE_OFFSET))
    (local.set $k (i32.const 0))
    (block $done (loop $loop
      (br_if $done (i32.ge_u (local.get $k) (local.get $n)))
      (local.set $angle (f64.mul (f64.convert_i32_u (local.get $k)) (local.get $neg_two_pi_over_n)))
      (f64.store (local.get $addr) (call $cos (local.get $angle)))
      (f64.store (i32.add (local.get $addr) (i32.const 8)) (call $sin (local.get $angle)))
      (local.set $addr (i32.add (local.get $addr) (i32.const 16)))
      (local.set $k (i32.add (local.get $k) (i32.const 1)))
      (br $loop)
    ))
  )

  ;; ============================================================================
  ;; SIMD Complex Multiply (for Stockham radix-2)
  ;; ============================================================================
  (func $simd_cmul (param $a v128) (param $b v128) (result v128)
    (local $ar v128) (local $ai v128) (local $bd v128)
    (local.set $ar (f64x2.splat (f64x2.extract_lane 0 (local.get $a))))
    (local.set $ai (f64x2.splat (f64x2.extract_lane 1 (local.get $a))))
    (local.set $bd (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $b) (local.get $b)))
    (f64x2.add
      (f64x2.mul (local.get $ar) (local.get $b))
      (f64x2.mul (v128.xor (local.get $ai) (global.get $SIGN_MASK)) (local.get $bd)))
  )

  ;; ============================================================================
  ;; N=4 Kernel (shared)
  ;; ============================================================================
  (func $fft_4
    (local $x0 v128) (local $x1 v128) (local $x2 v128) (local $x3 v128)
    (local $t0 v128) (local $t1 v128) (local $t2 v128) (local $t3 v128)
    (local.set $x0 (v128.load (i32.const 0)))
    (local.set $x1 (v128.load (i32.const 16)))
    (local.set $x2 (v128.load (i32.const 32)))
    (local.set $x3 (v128.load (i32.const 48)))
    (local.set $t0 (f64x2.add (local.get $x0) (local.get $x2)))
    (local.set $t1 (f64x2.sub (local.get $x0) (local.get $x2)))
    (local.set $t2 (f64x2.add (local.get $x1) (local.get $x3)))
    (local.set $t3 (f64x2.sub (local.get $x1) (local.get $x3)))
    (local.set $t3 (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $t3) (local.get $t3)) (v128.const f64x2 1.0 -1.0)))
    (v128.store (i32.const 0) (f64x2.add (local.get $t0) (local.get $t2)))
    (v128.store (i32.const 16) (f64x2.add (local.get $t1) (local.get $t3)))
    (v128.store (i32.const 32) (f64x2.sub (local.get $t0) (local.get $t2)))
    (v128.store (i32.const 48) (f64x2.sub (local.get $t1) (local.get $t3)))
  )

  ;; ============================================================================
  ;; Fused Real FFT N=8: 8 real inputs -> 5 complex outputs
  ;; Combines FFT-4 + post-processing with hardcoded twiddles
  ;; ============================================================================
  (func $rfft_8
    (local $z0 v128) (local $z1 v128) (local $z2 v128) (local $z3 v128)
    (local $t0 v128) (local $t1 v128) (local $t2 v128) (local $t3 v128)
    ;; Post-processing temporaries (scalars)
    (local $z0_re f64) (local $z0_im f64)
    (local $z1_re f64) (local $z1_im f64) (local $z3_re f64) (local $z3_im f64)
    (local $z2_re f64) (local $z2_im f64)
    (local $sum_re f64) (local $sum_im f64) (local $diff_re f64) (local $diff_im f64)
    (local $wd_re f64) (local $wd_im f64)

    ;; Load 4 complex values (8 real values interpreted as complex)
    (local.set $z0 (v128.load (i32.const 0)))
    (local.set $z1 (v128.load (i32.const 16)))
    (local.set $z2 (v128.load (i32.const 32)))
    (local.set $z3 (v128.load (i32.const 48)))

    ;; FFT-4 butterfly (same as $fft_4)
    (local.set $t0 (f64x2.add (local.get $z0) (local.get $z2)))
    (local.set $t1 (f64x2.sub (local.get $z0) (local.get $z2)))
    (local.set $t2 (f64x2.add (local.get $z1) (local.get $z3)))
    (local.set $t3 (f64x2.sub (local.get $z1) (local.get $z3)))
    ;; t3 = t3 * -i = (im, -re) -> swap and negate im
    (local.set $t3 (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $t3) (local.get $t3)) (v128.const f64x2 1.0 -1.0)))
    ;; FFT-4 outputs: z0 = t0+t2, z1 = t1+t3, z2 = t0-t2, z3 = t1-t3
    (local.set $z0 (f64x2.add (local.get $t0) (local.get $t2)))
    (local.set $z1 (f64x2.add (local.get $t1) (local.get $t3)))
    (local.set $z2 (f64x2.sub (local.get $t0) (local.get $t2)))
    (local.set $z3 (f64x2.sub (local.get $t1) (local.get $t3)))

    ;; ---- Post-processing with hardcoded twiddles ----
    ;; Extract scalar components
    (local.set $z0_re (f64x2.extract_lane 0 (local.get $z0)))
    (local.set $z0_im (f64x2.extract_lane 1 (local.get $z0)))
    (local.set $z1_re (f64x2.extract_lane 0 (local.get $z1)))
    (local.set $z1_im (f64x2.extract_lane 1 (local.get $z1)))
    (local.set $z2_re (f64x2.extract_lane 0 (local.get $z2)))
    (local.set $z2_im (f64x2.extract_lane 1 (local.get $z2)))
    (local.set $z3_re (f64x2.extract_lane 0 (local.get $z3)))
    (local.set $z3_im (f64x2.extract_lane 1 (local.get $z3)))

    ;; X[0] = (Z[0].re + Z[0].im, 0) - DC component
    (f64.store (i32.const 0) (f64.add (local.get $z0_re) (local.get $z0_im)))
    (f64.store (i32.const 8) (f64.const 0.0))

    ;; X[4] = (Z[0].re - Z[0].im, 0) - Nyquist component
    (f64.store (i32.const 64) (f64.sub (local.get $z0_re) (local.get $z0_im)))
    (f64.store (i32.const 72) (f64.const 0.0))

    ;; X[1] using Z[1] and Z[3] with W_8^1 = (0.7071067811865476, -0.7071067811865476)
    (local.set $sum_re (f64.add (local.get $z1_re) (local.get $z3_re)))
    (local.set $sum_im (f64.sub (local.get $z1_im) (local.get $z3_im)))
    (local.set $diff_re (f64.sub (local.get $z1_re) (local.get $z3_re)))
    (local.set $diff_im (f64.add (local.get $z1_im) (local.get $z3_im)))
    ;; wd = W.im * diff_re + W.re * diff_im, W.im * diff_im - W.re * diff_re
    ;; W_8^1.re = 0.7071067811865476, W_8^1.im = -0.7071067811865476
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.7071067811865476) (local.get $diff_re))
                               (f64.mul (f64.const 0.7071067811865476) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.7071067811865476) (local.get $diff_im))
                               (f64.mul (f64.const 0.7071067811865476) (local.get $diff_re))))
    (f64.store (i32.const 16) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 24) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))

    ;; X[3] using Z[3] and Z[1] with W_8^3 = (-0.7071067811865476, -0.7071067811865476)
    (local.set $sum_re (f64.add (local.get $z3_re) (local.get $z1_re)))
    (local.set $sum_im (f64.sub (local.get $z3_im) (local.get $z1_im)))
    (local.set $diff_re (f64.sub (local.get $z3_re) (local.get $z1_re)))
    (local.set $diff_im (f64.add (local.get $z3_im) (local.get $z1_im)))
    ;; W_8^3.re = -0.7071067811865476, W_8^3.im = -0.7071067811865476
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.7071067811865476) (local.get $diff_re))
                               (f64.mul (f64.const -0.7071067811865476) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.7071067811865476) (local.get $diff_im))
                               (f64.mul (f64.const -0.7071067811865476) (local.get $diff_re))))
    (f64.store (i32.const 48) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 56) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))

    ;; X[2] = conj(Z[2]) - middle element simplifies with W_8^2 = (0, -1)
    (f64.store (i32.const 32) (local.get $z2_re))
    (f64.store (i32.const 40) (f64.neg (local.get $z2_im)))
  )

  ;; ============================================================================
  ;; Fused Real FFT N=32: 32 real inputs -> 17 complex outputs
  ;; Calls fft_16 then does hardcoded post-processing (no twiddle memory loads)
  ;; ============================================================================
  (func $rfft_32
    (local $z0_re f64) (local $z0_im f64)
    (local $zk_re f64) (local $zk_im f64) (local $zn2k_re f64) (local $zn2k_im f64)
    (local $sum_re f64) (local $sum_im f64) (local $diff_re f64) (local $diff_im f64)
    (local $wd_re f64) (local $wd_im f64)
    (local $xk_re f64) (local $xk_im f64) (local $xn2k_re f64) (local $xn2k_im f64)
    ;; W_32^k twiddles hardcoded as pairs (re, im)
    ;; k=1: (0.9807852804032304, -0.19509032201612825)
    ;; k=2: (0.9238795325112867, -0.3826834323650898)
    ;; k=3: (0.8314696123025452, -0.5555702330196022)
    ;; k=4: (0.7071067811865476, -0.7071067811865476)
    ;; k=5: (0.5555702330196023, -0.8314696123025452)
    ;; k=6: (0.38268343236508984, -0.9238795325112867)
    ;; k=7: (0.19509032201612833, -0.9807852804032304)
    ;; k=8: (0, -1)  - middle element
    ;; k=9: (-0.19509032201612833, -0.9807852804032304)
    ;; ... conjugate symmetry for k=9..15

    ;; Run 16-point complex FFT
    (call $fft_16)

    ;; Post-processing: DC and Nyquist
    (local.set $z0_re (f64.load (i32.const 0)))
    (local.set $z0_im (f64.load (i32.const 8)))
    (f64.store (i32.const 0) (f64.add (local.get $z0_re) (local.get $z0_im)))
    (f64.store (i32.const 8) (f64.const 0.0))
    (f64.store (i32.const 256) (f64.sub (local.get $z0_re) (local.get $z0_im)))  ;; X[16] at offset 16*16=256
    (f64.store (i32.const 264) (f64.const 0.0))

    ;; k=1: Z[1] at 16, Z[15] at 240, W_32^1=(0.9807852804032304, -0.19509032201612825), W_32^15=(-0.9807852804032304, -0.19509032201612833)
    (local.set $zk_re (f64.load (i32.const 16)))
    (local.set $zk_im (f64.load (i32.const 24)))
    (local.set $zn2k_re (f64.load (i32.const 240)))
    (local.set $zn2k_im (f64.load (i32.const 248)))
    (local.set $sum_re (f64.add (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $sum_im (f64.sub (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $diff_re (f64.sub (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $diff_im (f64.add (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.19509032201612825) (local.get $diff_re)) (f64.mul (f64.const 0.9807852804032304) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.19509032201612825) (local.get $diff_im)) (f64.mul (f64.const 0.9807852804032304) (local.get $diff_re))))
    (f64.store (i32.const 16) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 24) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))
    ;; X[15] - W_32^15=(-0.9807852804032304, -0.19509032201612833) -> use (W.im, W.re)
    (local.set $sum_re (f64.add (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $sum_im (f64.sub (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $diff_re (f64.sub (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $diff_im (f64.add (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.19509032201612833) (local.get $diff_re)) (f64.mul (f64.const -0.9807852804032304) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.19509032201612833) (local.get $diff_im)) (f64.mul (f64.const -0.9807852804032304) (local.get $diff_re))))
    (f64.store (i32.const 240) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 248) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))

    ;; k=2: Z[2] at 32, Z[14] at 224, W_32^2=(0.9238795325112867, -0.3826834323650898), W_32^14=(-0.9238795325112867, -0.3826834323650898)
    (local.set $zk_re (f64.load (i32.const 32)))
    (local.set $zk_im (f64.load (i32.const 40)))
    (local.set $zn2k_re (f64.load (i32.const 224)))
    (local.set $zn2k_im (f64.load (i32.const 232)))
    (local.set $sum_re (f64.add (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $sum_im (f64.sub (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $diff_re (f64.sub (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $diff_im (f64.add (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.3826834323650898) (local.get $diff_re)) (f64.mul (f64.const 0.9238795325112867) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.3826834323650898) (local.get $diff_im)) (f64.mul (f64.const 0.9238795325112867) (local.get $diff_re))))
    (f64.store (i32.const 32) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 40) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))
    ;; X[14] - W_32^14=(-0.9238795325112867, -0.3826834323650898) -> use (W.im, W.re)
    (local.set $sum_re (f64.add (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $sum_im (f64.sub (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $diff_re (f64.sub (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $diff_im (f64.add (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.3826834323650898) (local.get $diff_re)) (f64.mul (f64.const -0.9238795325112867) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.3826834323650898) (local.get $diff_im)) (f64.mul (f64.const -0.9238795325112867) (local.get $diff_re))))
    (f64.store (i32.const 224) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 232) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))

    ;; k=3: Z[3] at 48, Z[13] at 208, W_32^3=(0.8314696123025452, -0.5555702330196022), W_32^13=(-0.8314696123025452, -0.5555702330196022)
    (local.set $zk_re (f64.load (i32.const 48)))
    (local.set $zk_im (f64.load (i32.const 56)))
    (local.set $zn2k_re (f64.load (i32.const 208)))
    (local.set $zn2k_im (f64.load (i32.const 216)))
    (local.set $sum_re (f64.add (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $sum_im (f64.sub (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $diff_re (f64.sub (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $diff_im (f64.add (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.5555702330196022) (local.get $diff_re)) (f64.mul (f64.const 0.8314696123025452) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.5555702330196022) (local.get $diff_im)) (f64.mul (f64.const 0.8314696123025452) (local.get $diff_re))))
    (f64.store (i32.const 48) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 56) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))
    ;; X[13] - W_32^13=(-0.8314696123025452, -0.5555702330196022) -> use (W.im, W.re)
    (local.set $sum_re (f64.add (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $sum_im (f64.sub (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $diff_re (f64.sub (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $diff_im (f64.add (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.5555702330196022) (local.get $diff_re)) (f64.mul (f64.const -0.8314696123025452) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.5555702330196022) (local.get $diff_im)) (f64.mul (f64.const -0.8314696123025452) (local.get $diff_re))))
    (f64.store (i32.const 208) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 216) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))

    ;; k=4: Z[4] at 64, Z[12] at 192, W_32^4=(0.7071067811865476, -0.7071067811865476), W_32^12=(-0.7071067811865476, -0.7071067811865476)
    (local.set $zk_re (f64.load (i32.const 64)))
    (local.set $zk_im (f64.load (i32.const 72)))
    (local.set $zn2k_re (f64.load (i32.const 192)))
    (local.set $zn2k_im (f64.load (i32.const 200)))
    (local.set $sum_re (f64.add (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $sum_im (f64.sub (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $diff_re (f64.sub (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $diff_im (f64.add (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.7071067811865476) (local.get $diff_re)) (f64.mul (f64.const 0.7071067811865476) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.7071067811865476) (local.get $diff_im)) (f64.mul (f64.const 0.7071067811865476) (local.get $diff_re))))
    (f64.store (i32.const 64) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 72) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))
    ;; X[12]
    (local.set $sum_re (f64.add (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $sum_im (f64.sub (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $diff_re (f64.sub (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $diff_im (f64.add (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.7071067811865476) (local.get $diff_re)) (f64.mul (f64.const -0.7071067811865476) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.7071067811865476) (local.get $diff_im)) (f64.mul (f64.const -0.7071067811865476) (local.get $diff_re))))
    (f64.store (i32.const 192) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 200) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))

    ;; k=5: Z[5] at 80, Z[11] at 176, W_32^5=(0.5555702330196023, -0.8314696123025452), W_32^11=(-0.5555702330196023, -0.8314696123025452)
    (local.set $zk_re (f64.load (i32.const 80)))
    (local.set $zk_im (f64.load (i32.const 88)))
    (local.set $zn2k_re (f64.load (i32.const 176)))
    (local.set $zn2k_im (f64.load (i32.const 184)))
    (local.set $sum_re (f64.add (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $sum_im (f64.sub (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $diff_re (f64.sub (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $diff_im (f64.add (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.8314696123025452) (local.get $diff_re)) (f64.mul (f64.const 0.5555702330196023) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.8314696123025452) (local.get $diff_im)) (f64.mul (f64.const 0.5555702330196023) (local.get $diff_re))))
    (f64.store (i32.const 80) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 88) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))
    ;; X[11] - W_32^11=(-0.5555702330196023, -0.8314696123025452) -> use (W.im, W.re)
    (local.set $sum_re (f64.add (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $sum_im (f64.sub (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $diff_re (f64.sub (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $diff_im (f64.add (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.8314696123025452) (local.get $diff_re)) (f64.mul (f64.const -0.5555702330196023) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.8314696123025452) (local.get $diff_im)) (f64.mul (f64.const -0.5555702330196023) (local.get $diff_re))))
    (f64.store (i32.const 176) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 184) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))

    ;; k=6: Z[6] at 96, Z[10] at 160, W_32^6=(0.38268343236508984, -0.9238795325112867), W_32^10=(-0.3826834323650898, -0.9238795325112867)
    (local.set $zk_re (f64.load (i32.const 96)))
    (local.set $zk_im (f64.load (i32.const 104)))
    (local.set $zn2k_re (f64.load (i32.const 160)))
    (local.set $zn2k_im (f64.load (i32.const 168)))
    (local.set $sum_re (f64.add (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $sum_im (f64.sub (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $diff_re (f64.sub (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $diff_im (f64.add (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.9238795325112867) (local.get $diff_re)) (f64.mul (f64.const 0.38268343236508984) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.9238795325112867) (local.get $diff_im)) (f64.mul (f64.const 0.38268343236508984) (local.get $diff_re))))
    (f64.store (i32.const 96) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 104) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))
    ;; X[10] - W_32^10=(-0.3826834323650898, -0.9238795325112867) -> use (W.im, W.re)
    (local.set $sum_re (f64.add (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $sum_im (f64.sub (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $diff_re (f64.sub (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $diff_im (f64.add (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.9238795325112867) (local.get $diff_re)) (f64.mul (f64.const -0.38268343236508984) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.9238795325112867) (local.get $diff_im)) (f64.mul (f64.const -0.38268343236508984) (local.get $diff_re))))
    (f64.store (i32.const 160) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 168) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))

    ;; k=7: Z[7] at 112, Z[9] at 144, W_32^7=(0.19509032201612833, -0.9807852804032304), W_32^9=(-0.19509032201612833, -0.9807852804032304)
    (local.set $zk_re (f64.load (i32.const 112)))
    (local.set $zk_im (f64.load (i32.const 120)))
    (local.set $zn2k_re (f64.load (i32.const 144)))
    (local.set $zn2k_im (f64.load (i32.const 152)))
    (local.set $sum_re (f64.add (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $sum_im (f64.sub (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $diff_re (f64.sub (local.get $zk_re) (local.get $zn2k_re)))
    (local.set $diff_im (f64.add (local.get $zk_im) (local.get $zn2k_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.9807852804032304) (local.get $diff_re)) (f64.mul (f64.const 0.19509032201612833) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.9807852804032304) (local.get $diff_im)) (f64.mul (f64.const 0.19509032201612833) (local.get $diff_re))))
    (f64.store (i32.const 112) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 120) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))
    ;; X[9] - W_32^9=(-0.19509032201612833, -0.9807852804032304) -> use (W.im, W.re)
    (local.set $sum_re (f64.add (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $sum_im (f64.sub (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $diff_re (f64.sub (local.get $zn2k_re) (local.get $zk_re)))
    (local.set $diff_im (f64.add (local.get $zn2k_im) (local.get $zk_im)))
    (local.set $wd_re (f64.add (f64.mul (f64.const -0.9807852804032304) (local.get $diff_re)) (f64.mul (f64.const -0.19509032201612833) (local.get $diff_im))))
    (local.set $wd_im (f64.sub (f64.mul (f64.const -0.9807852804032304) (local.get $diff_im)) (f64.mul (f64.const -0.19509032201612833) (local.get $diff_re))))
    (f64.store (i32.const 144) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
    (f64.store (i32.const 152) (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))

    ;; k=8 (middle): Z[8] at 128, W_32^8=(0, -1) -> simplifies to X[8] = conj(Z[8])
    (local.set $zk_re (f64.load (i32.const 128)))
    (local.set $zk_im (f64.load (i32.const 136)))
    (f64.store (i32.const 128) (local.get $zk_re))
    (f64.store (i32.const 136) (f64.neg (local.get $zk_im)))
  )

  ;; ============================================================================
  ;; SIMD Post-Processing for Real FFT (used for N >= 128)
  ;; Uses SIMD operations for the conjugate-split computation:
  ;;   sum = Z[k] + conj(Z[n2-k])
  ;;   diff = Z[k] - conj(Z[n2-k])
  ;;   wd = W_rot * diff (where W_rot = (w_im, -w_re))
  ;;   X[k] = 0.5 * (sum + wd)
  ;; ============================================================================
  (func $rfft_postprocess_simd (param $n2 i32)
    (local $k i32) (local $k_end i32) (local $n2_minus_k i32)
    (local $addr_k i32) (local $addr_n2k i32) (local $tw_addr i32)
    (local $zk v128) (local $zn2k v128) (local $conj_zn2k v128)
    (local $wk v128) (local $wk_rot v128)
    (local $wn2k v128) (local $wn2k_rot v128)
    (local $sum v128) (local $diff v128) (local $wd v128)
    (local $sum2 v128) (local $diff2 v128) (local $wd2 v128)
    (local $xk v128) (local $xn2k v128)
    (local $z0 v128) (local $z0_re f64) (local $z0_im f64)
    (local $half v128)
    (local $conj_zk v128)

    (local.set $half (v128.const f64x2 0.5 0.5))

    ;; DC and Nyquist handling
    (local.set $z0 (v128.load (i32.const 0)))
    (local.set $z0_re (f64x2.extract_lane 0 (local.get $z0)))
    (local.set $z0_im (f64x2.extract_lane 1 (local.get $z0)))
    (f64.store (i32.const 0) (f64.add (local.get $z0_re) (local.get $z0_im)))
    (f64.store (i32.const 8) (f64.const 0.0))
    (local.set $addr_k (i32.shl (local.get $n2) (i32.const 4)))
    (f64.store (local.get $addr_k) (f64.sub (local.get $z0_re) (local.get $z0_im)))
    (f64.store (i32.add (local.get $addr_k) (i32.const 8)) (f64.const 0.0))

    ;; Main SIMD loop for pairs
    (local.set $k_end (i32.shr_u (local.get $n2) (i32.const 1)))
    (local.set $k (i32.const 1))
    (block $done_main (loop $main_loop
      (br_if $done_main (i32.ge_u (local.get $k) (local.get $k_end)))
      (local.set $n2_minus_k (i32.sub (local.get $n2) (local.get $k)))
      (local.set $addr_k (i32.shl (local.get $k) (i32.const 4)))
      (local.set $addr_n2k (i32.shl (local.get $n2_minus_k) (i32.const 4)))

      ;; Load Z[k] and Z[n2-k] as v128
      (local.set $zk (v128.load (local.get $addr_k)))
      (local.set $zn2k (v128.load (local.get $addr_n2k)))

      ;; Compute conj(Z[n2-k]) = (re, -im)
      (local.set $conj_zn2k (v128.xor (local.get $zn2k) (global.get $CONJ_MASK)))

      ;; sum = Z[k] + conj(Z[n2-k])
      ;; diff = Z[k] - conj(Z[n2-k])
      (local.set $sum (f64x2.add (local.get $zk) (local.get $conj_zn2k)))
      (local.set $diff (f64x2.sub (local.get $zk) (local.get $conj_zn2k)))

      ;; Load W[k] and create W_rot = (w_im, -w_re) using shuffle and sign flip
      (local.set $tw_addr (i32.add (global.get $RFFT_TWIDDLE_OFFSET) (i32.shl (local.get $k) (i32.const 4))))
      (local.set $wk (v128.load (local.get $tw_addr)))
      ;; W_rot = (w_im, -w_re): shuffle to (w_im, w_re) then flip sign of second lane
      (local.set $wk_rot (v128.xor
        (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $wk) (local.get $wk))
        (global.get $CONJ_MASK)))

      ;; wd = W_rot * diff (standard complex multiply)
      ;; Using inlined simd_cmul pattern
      (local.set $wd (f64x2.add
        (f64x2.mul (local.get $diff)
          (i8x16.shuffle 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 (local.get $wk_rot) (local.get $wk_rot)))
        (f64x2.mul
          (f64x2.mul
            (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $diff) (local.get $diff))
            (i8x16.shuffle 8 9 10 11 12 13 14 15 8 9 10 11 12 13 14 15 (local.get $wk_rot) (local.get $wk_rot)))
          (v128.const f64x2 -1.0 1.0))))

      ;; X[k] = 0.5 * (sum + wd)
      (local.set $xk (f64x2.mul (f64x2.add (local.get $sum) (local.get $wd)) (local.get $half)))

      ;; Now compute X[n2-k] using swapped inputs
      ;; conj(Z[k]) = (re, -im)
      (local.set $conj_zk (v128.xor (local.get $zk) (global.get $CONJ_MASK)))

      ;; sum2 = Z[n2-k] + conj(Z[k])
      ;; diff2 = Z[n2-k] - conj(Z[k])
      (local.set $sum2 (f64x2.add (local.get $zn2k) (local.get $conj_zk)))
      (local.set $diff2 (f64x2.sub (local.get $zn2k) (local.get $conj_zk)))

      ;; Load W[n2-k] and create W_rot2
      (local.set $tw_addr (i32.add (global.get $RFFT_TWIDDLE_OFFSET) (i32.shl (local.get $n2_minus_k) (i32.const 4))))
      (local.set $wn2k (v128.load (local.get $tw_addr)))
      (local.set $wn2k_rot (v128.xor
        (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $wn2k) (local.get $wn2k))
        (global.get $CONJ_MASK)))

      ;; wd2 = W_rot2 * diff2
      (local.set $wd2 (f64x2.add
        (f64x2.mul (local.get $diff2)
          (i8x16.shuffle 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 (local.get $wn2k_rot) (local.get $wn2k_rot)))
        (f64x2.mul
          (f64x2.mul
            (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $diff2) (local.get $diff2))
            (i8x16.shuffle 8 9 10 11 12 13 14 15 8 9 10 11 12 13 14 15 (local.get $wn2k_rot) (local.get $wn2k_rot)))
          (v128.const f64x2 -1.0 1.0))))

      ;; X[n2-k] = 0.5 * (sum2 + wd2)
      (local.set $xn2k (f64x2.mul (f64x2.add (local.get $sum2) (local.get $wd2)) (local.get $half)))

      ;; Store results
      (v128.store (local.get $addr_k) (local.get $xk))
      (v128.store (local.get $addr_n2k) (local.get $xn2k))

      (local.set $k (i32.add (local.get $k) (i32.const 1)))
      (br $main_loop)
    ))

    ;; Handle middle element (when n2 is even and > 2)
    (if (i32.and (i32.eqz (i32.and (local.get $n2) (i32.const 1))) (i32.gt_u (local.get $n2) (i32.const 2)))
      (then
        (local.set $addr_k (i32.shl (local.get $k_end) (i32.const 4)))
        (local.set $zk (v128.load (local.get $addr_k)))
        (local.set $tw_addr (i32.add (global.get $RFFT_TWIDDLE_OFFSET) (i32.shl (local.get $k_end) (i32.const 4))))
        (local.set $wk (v128.load (local.get $tw_addr)))

        ;; For middle element k = n2/2, z[k] = z[n2-k] (it's the same element)
        ;; sum = z[k] + conj(z[k]) = (2*re, 0)
        ;; diff = z[k] - conj(z[k]) = (0, 2*im)
        (local.set $conj_zk (v128.xor (local.get $zk) (global.get $CONJ_MASK)))
        (local.set $sum (f64x2.add (local.get $zk) (local.get $conj_zk)))
        (local.set $diff (f64x2.sub (local.get $zk) (local.get $conj_zk)))

        ;; W_rot * diff
        (local.set $wk_rot (v128.xor
          (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $wk) (local.get $wk))
          (global.get $CONJ_MASK)))
        (local.set $wd (f64x2.add
          (f64x2.mul (local.get $diff)
            (i8x16.shuffle 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 (local.get $wk_rot) (local.get $wk_rot)))
          (f64x2.mul
            (f64x2.mul
              (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $diff) (local.get $diff))
              (i8x16.shuffle 8 9 10 11 12 13 14 15 8 9 10 11 12 13 14 15 (local.get $wk_rot) (local.get $wk_rot)))
            (v128.const f64x2 -1.0 1.0))))

        (local.set $xk (f64x2.mul (f64x2.add (local.get $sum) (local.get $wd)) (local.get $half)))
        (v128.store (local.get $addr_k) (local.get $xk))
      )
    )
  )

  ;; ============================================================================
  ;; Radix-4: N=16 Fully Unrolled
  ;; ============================================================================
  (func $fft_16
    (local $x0 v128) (local $x1 v128) (local $x2 v128) (local $x3 v128)
    (local $x4 v128) (local $x5 v128) (local $x6 v128) (local $x7 v128)
    (local $x8 v128) (local $x9 v128) (local $x10 v128) (local $x11 v128)
    (local $x12 v128) (local $x13 v128) (local $x14 v128) (local $x15 v128)
    (local $t0 v128) (local $t1 v128) (local $t2 v128) (local $t3 v128)
    (local $tmp v128)

    (local.set $x0 (v128.load (i32.const 0)))
    (local.set $x1 (v128.load (i32.const 16)))
    (local.set $x2 (v128.load (i32.const 32)))
    (local.set $x3 (v128.load (i32.const 48)))
    (local.set $x4 (v128.load (i32.const 64)))
    (local.set $x5 (v128.load (i32.const 80)))
    (local.set $x6 (v128.load (i32.const 96)))
    (local.set $x7 (v128.load (i32.const 112)))
    (local.set $x8 (v128.load (i32.const 128)))
    (local.set $x9 (v128.load (i32.const 144)))
    (local.set $x10 (v128.load (i32.const 160)))
    (local.set $x11 (v128.load (i32.const 176)))
    (local.set $x12 (v128.load (i32.const 192)))
    (local.set $x13 (v128.load (i32.const 208)))
    (local.set $x14 (v128.load (i32.const 224)))
    (local.set $x15 (v128.load (i32.const 240)))

    ;; Stage 1: Four radix-4 butterflies
    (local.set $t0 (f64x2.add (local.get $x0) (local.get $x8)))
    (local.set $t1 (f64x2.sub (local.get $x0) (local.get $x8)))
    (local.set $t2 (f64x2.add (local.get $x4) (local.get $x12)))
    (local.set $t3 (f64x2.sub (local.get $x4) (local.get $x12)))
    (local.set $t3 (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $t3) (local.get $t3)) (v128.const f64x2 1.0 -1.0)))
    (local.set $x0 (f64x2.add (local.get $t0) (local.get $t2)))
    (local.set $x4 (f64x2.add (local.get $t1) (local.get $t3)))
    (local.set $x8 (f64x2.sub (local.get $t0) (local.get $t2)))
    (local.set $x12 (f64x2.sub (local.get $t1) (local.get $t3)))

    (local.set $t0 (f64x2.add (local.get $x1) (local.get $x9)))
    (local.set $t1 (f64x2.sub (local.get $x1) (local.get $x9)))
    (local.set $t2 (f64x2.add (local.get $x5) (local.get $x13)))
    (local.set $t3 (f64x2.sub (local.get $x5) (local.get $x13)))
    (local.set $t3 (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $t3) (local.get $t3)) (v128.const f64x2 1.0 -1.0)))
    (local.set $x1 (f64x2.add (local.get $t0) (local.get $t2)))
    (local.set $x5 (f64x2.add (local.get $t1) (local.get $t3)))
    (local.set $x9 (f64x2.sub (local.get $t0) (local.get $t2)))
    (local.set $x13 (f64x2.sub (local.get $t1) (local.get $t3)))

    (local.set $t0 (f64x2.add (local.get $x2) (local.get $x10)))
    (local.set $t1 (f64x2.sub (local.get $x2) (local.get $x10)))
    (local.set $t2 (f64x2.add (local.get $x6) (local.get $x14)))
    (local.set $t3 (f64x2.sub (local.get $x6) (local.get $x14)))
    (local.set $t3 (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $t3) (local.get $t3)) (v128.const f64x2 1.0 -1.0)))
    (local.set $x2 (f64x2.add (local.get $t0) (local.get $t2)))
    (local.set $x6 (f64x2.add (local.get $t1) (local.get $t3)))
    (local.set $x10 (f64x2.sub (local.get $t0) (local.get $t2)))
    (local.set $x14 (f64x2.sub (local.get $t1) (local.get $t3)))

    (local.set $t0 (f64x2.add (local.get $x3) (local.get $x11)))
    (local.set $t1 (f64x2.sub (local.get $x3) (local.get $x11)))
    (local.set $t2 (f64x2.add (local.get $x7) (local.get $x15)))
    (local.set $t3 (f64x2.sub (local.get $x7) (local.get $x15)))
    (local.set $t3 (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $t3) (local.get $t3)) (v128.const f64x2 1.0 -1.0)))
    (local.set $x3 (f64x2.add (local.get $t0) (local.get $t2)))
    (local.set $x7 (f64x2.add (local.get $t1) (local.get $t3)))
    (local.set $x11 (f64x2.sub (local.get $t0) (local.get $t2)))
    (local.set $x15 (f64x2.sub (local.get $t1) (local.get $t3)))

    ;; Stage 2 with twiddles
    (local.set $t0 (f64x2.add (local.get $x0) (local.get $x2)))
    (local.set $t1 (f64x2.sub (local.get $x0) (local.get $x2)))
    (local.set $t2 (f64x2.add (local.get $x1) (local.get $x3)))
    (local.set $t3 (f64x2.sub (local.get $x1) (local.get $x3)))
    (local.set $t3 (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $t3) (local.get $t3)) (v128.const f64x2 1.0 -1.0)))
    (v128.store (i32.const 0) (f64x2.add (local.get $t0) (local.get $t2)))
    (v128.store (i32.const 64) (f64x2.add (local.get $t1) (local.get $t3)))
    (v128.store (i32.const 128) (f64x2.sub (local.get $t0) (local.get $t2)))
    (v128.store (i32.const 192) (f64x2.sub (local.get $t1) (local.get $t3)))

    (local.set $tmp (local.get $x5))
    (local.set $x5 (f64x2.add (f64x2.mul (local.get $tmp) (v128.const f64x2 0.9238795325112867 0.9238795325112867)) (f64x2.mul (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $tmp) (local.get $tmp)) (v128.const f64x2 -0.3826834323650898 -0.3826834323650898)) (v128.const f64x2 -1.0 1.0))))
    (local.set $tmp (local.get $x6))
    (local.set $x6 (f64x2.add (f64x2.mul (local.get $tmp) (v128.const f64x2 0.7071067811865476 0.7071067811865476)) (f64x2.mul (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $tmp) (local.get $tmp)) (v128.const f64x2 -0.7071067811865476 -0.7071067811865476)) (v128.const f64x2 -1.0 1.0))))
    (local.set $tmp (local.get $x7))
    (local.set $x7 (f64x2.add (f64x2.mul (local.get $tmp) (v128.const f64x2 0.3826834323650898 0.3826834323650898)) (f64x2.mul (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $tmp) (local.get $tmp)) (v128.const f64x2 -0.9238795325112867 -0.9238795325112867)) (v128.const f64x2 -1.0 1.0))))
    (local.set $t0 (f64x2.add (local.get $x4) (local.get $x6)))
    (local.set $t1 (f64x2.sub (local.get $x4) (local.get $x6)))
    (local.set $t2 (f64x2.add (local.get $x5) (local.get $x7)))
    (local.set $t3 (f64x2.sub (local.get $x5) (local.get $x7)))
    (local.set $t3 (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $t3) (local.get $t3)) (v128.const f64x2 1.0 -1.0)))
    (v128.store (i32.const 16) (f64x2.add (local.get $t0) (local.get $t2)))
    (v128.store (i32.const 80) (f64x2.add (local.get $t1) (local.get $t3)))
    (v128.store (i32.const 144) (f64x2.sub (local.get $t0) (local.get $t2)))
    (v128.store (i32.const 208) (f64x2.sub (local.get $t1) (local.get $t3)))

    (local.set $tmp (local.get $x9))
    (local.set $x9 (f64x2.add (f64x2.mul (local.get $tmp) (v128.const f64x2 0.7071067811865476 0.7071067811865476)) (f64x2.mul (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $tmp) (local.get $tmp)) (v128.const f64x2 -0.7071067811865476 -0.7071067811865476)) (v128.const f64x2 -1.0 1.0))))
    (local.set $x10 (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $x10) (local.get $x10)) (v128.const f64x2 1.0 -1.0)))
    (local.set $tmp (local.get $x11))
    (local.set $x11 (f64x2.add (f64x2.mul (local.get $tmp) (v128.const f64x2 -0.7071067811865476 -0.7071067811865476)) (f64x2.mul (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $tmp) (local.get $tmp)) (v128.const f64x2 -0.7071067811865476 -0.7071067811865476)) (v128.const f64x2 -1.0 1.0))))
    (local.set $t0 (f64x2.add (local.get $x8) (local.get $x10)))
    (local.set $t1 (f64x2.sub (local.get $x8) (local.get $x10)))
    (local.set $t2 (f64x2.add (local.get $x9) (local.get $x11)))
    (local.set $t3 (f64x2.sub (local.get $x9) (local.get $x11)))
    (local.set $t3 (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $t3) (local.get $t3)) (v128.const f64x2 1.0 -1.0)))
    (v128.store (i32.const 32) (f64x2.add (local.get $t0) (local.get $t2)))
    (v128.store (i32.const 96) (f64x2.add (local.get $t1) (local.get $t3)))
    (v128.store (i32.const 160) (f64x2.sub (local.get $t0) (local.get $t2)))
    (v128.store (i32.const 224) (f64x2.sub (local.get $t1) (local.get $t3)))

    (local.set $tmp (local.get $x13))
    (local.set $x13 (f64x2.add (f64x2.mul (local.get $tmp) (v128.const f64x2 0.3826834323650898 0.3826834323650898)) (f64x2.mul (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $tmp) (local.get $tmp)) (v128.const f64x2 -0.9238795325112867 -0.9238795325112867)) (v128.const f64x2 -1.0 1.0))))
    (local.set $tmp (local.get $x14))
    (local.set $x14 (f64x2.add (f64x2.mul (local.get $tmp) (v128.const f64x2 -0.7071067811865476 -0.7071067811865476)) (f64x2.mul (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $tmp) (local.get $tmp)) (v128.const f64x2 -0.7071067811865476 -0.7071067811865476)) (v128.const f64x2 -1.0 1.0))))
    (local.set $tmp (local.get $x15))
    (local.set $x15 (f64x2.add (f64x2.mul (local.get $tmp) (v128.const f64x2 -0.9238795325112867 -0.9238795325112867)) (f64x2.mul (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $tmp) (local.get $tmp)) (v128.const f64x2 0.3826834323650898 0.3826834323650898)) (v128.const f64x2 -1.0 1.0))))
    (local.set $t0 (f64x2.add (local.get $x12) (local.get $x14)))
    (local.set $t1 (f64x2.sub (local.get $x12) (local.get $x14)))
    (local.set $t2 (f64x2.add (local.get $x13) (local.get $x15)))
    (local.set $t3 (f64x2.sub (local.get $x13) (local.get $x15)))
    (local.set $t3 (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $t3) (local.get $t3)) (v128.const f64x2 1.0 -1.0)))
    (v128.store (i32.const 48) (f64x2.add (local.get $t0) (local.get $t2)))
    (v128.store (i32.const 112) (f64x2.add (local.get $t1) (local.get $t3)))
    (v128.store (i32.const 176) (f64x2.sub (local.get $t0) (local.get $t2)))
    (v128.store (i32.const 240) (f64x2.sub (local.get $t1) (local.get $t3)))
  )

  ;; ============================================================================
  ;; Radix-4: General FFT for N >= 64
  ;; ============================================================================
  (func $fft_radix4_general (param $n i32)
    (local $n4 i32) (local $r i32) (local $l i32) (local $j i32) (local $k i32)
    (local $src i32) (local $dst i32) (local $tw_step i32)
    (local $i0 i32) (local $i1 i32) (local $i2 i32) (local $i3 i32)
    (local $o0 i32) (local $o1 i32) (local $o2 i32) (local $o3 i32)
    (local $w1 v128) (local $w2 v128) (local $w3 v128)
    (local $tw_idx i32) (local $tw_addr i32)
    (local $a v128) (local $b v128) (local $c v128) (local $d v128)
    (local $b1 v128) (local $c1 v128) (local $d1 v128)
    (local $t0 v128) (local $t1 v128) (local $t2 v128) (local $t3 v128)
    (local $r_bytes i32) (local $n4_bytes i32)

    (local.set $n4 (i32.shr_u (local.get $n) (i32.const 2)))
    (local.set $n4_bytes (i32.shl (local.get $n4) (i32.const 4)))
    (local.set $src (i32.const 0))
    (local.set $dst (global.get $SECONDARY_OFFSET))
    (local.set $r (local.get $n4))
    (local.set $l (i32.const 1))

    (block $done_stages (loop $stage_loop
      (br_if $done_stages (i32.lt_u (local.get $r) (i32.const 1)))
      (local.set $r_bytes (i32.shl (local.get $r) (i32.const 4)))
      (local.set $tw_step (i32.div_u (local.get $n) (i32.shl (local.get $l) (i32.const 2))))
      (local.set $j (i32.const 0))
      (local.set $o0 (local.get $dst))
      (local.set $o1 (i32.add (local.get $dst) (local.get $n4_bytes)))
      (local.set $o2 (i32.add (local.get $o1) (local.get $n4_bytes)))
      (local.set $o3 (i32.add (local.get $o2) (local.get $n4_bytes)))
      (local.set $i0 (local.get $src))

      (block $done_groups (loop $group_loop
        (br_if $done_groups (i32.ge_u (local.get $j) (local.get $l)))
        (local.set $tw_idx (i32.mul (local.get $j) (local.get $tw_step)))
        (local.set $tw_addr (i32.add (global.get $TWIDDLE_OFFSET) (i32.shl (local.get $tw_idx) (i32.const 4))))
        (local.set $w1 (v128.load (local.get $tw_addr)))
        (local.set $tw_addr (i32.add (global.get $TWIDDLE_OFFSET) (i32.shl (i32.mul (local.get $tw_idx) (i32.const 2)) (i32.const 4))))
        (if (i32.ge_u (i32.mul (local.get $tw_idx) (i32.const 2)) (local.get $n))
          (then (local.set $tw_addr (i32.add (global.get $TWIDDLE_OFFSET) (i32.shl (i32.sub (i32.mul (local.get $tw_idx) (i32.const 2)) (local.get $n)) (i32.const 4))))))
        (local.set $w2 (v128.load (local.get $tw_addr)))
        (local.set $tw_addr (i32.add (global.get $TWIDDLE_OFFSET) (i32.shl (i32.mul (local.get $tw_idx) (i32.const 3)) (i32.const 4))))
        (if (i32.ge_u (i32.mul (local.get $tw_idx) (i32.const 3)) (local.get $n))
          (then (local.set $tw_addr (i32.add (global.get $TWIDDLE_OFFSET) (i32.shl (i32.rem_u (i32.mul (local.get $tw_idx) (i32.const 3)) (local.get $n)) (i32.const 4))))))
        (local.set $w3 (v128.load (local.get $tw_addr)))
        (local.set $i1 (i32.add (local.get $i0) (local.get $r_bytes)))
        (local.set $i2 (i32.add (local.get $i1) (local.get $r_bytes)))
        (local.set $i3 (i32.add (local.get $i2) (local.get $r_bytes)))
        (local.set $k (i32.const 0))

        (block $done_butterflies (loop $butterfly_loop
          (br_if $done_butterflies (i32.ge_u (local.get $k) (local.get $r)))
          (local.set $a (v128.load (local.get $i0)))
          (local.set $b (v128.load (local.get $i1)))
          (local.set $c (v128.load (local.get $i2)))
          (local.set $d (v128.load (local.get $i3)))
          (local.set $b1 (f64x2.add (f64x2.mul (local.get $b) (i8x16.shuffle 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 (local.get $w1) (local.get $w1))) (f64x2.mul (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $b) (local.get $b)) (i8x16.shuffle 8 9 10 11 12 13 14 15 8 9 10 11 12 13 14 15 (local.get $w1) (local.get $w1))) (v128.const f64x2 -1.0 1.0))))
          (local.set $c1 (f64x2.add (f64x2.mul (local.get $c) (i8x16.shuffle 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 (local.get $w2) (local.get $w2))) (f64x2.mul (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $c) (local.get $c)) (i8x16.shuffle 8 9 10 11 12 13 14 15 8 9 10 11 12 13 14 15 (local.get $w2) (local.get $w2))) (v128.const f64x2 -1.0 1.0))))
          (local.set $d1 (f64x2.add (f64x2.mul (local.get $d) (i8x16.shuffle 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 (local.get $w3) (local.get $w3))) (f64x2.mul (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $d) (local.get $d)) (i8x16.shuffle 8 9 10 11 12 13 14 15 8 9 10 11 12 13 14 15 (local.get $w3) (local.get $w3))) (v128.const f64x2 -1.0 1.0))))
          (local.set $t0 (f64x2.add (local.get $a) (local.get $c1)))
          (local.set $t1 (f64x2.sub (local.get $a) (local.get $c1)))
          (local.set $t2 (f64x2.add (local.get $b1) (local.get $d1)))
          (local.set $t3 (f64x2.sub (local.get $b1) (local.get $d1)))
          (v128.store (local.get $o0) (f64x2.add (local.get $t0) (local.get $t2)))
          (v128.store (local.get $o1) (f64x2.add (local.get $t1) (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $t3) (local.get $t3)) (v128.const f64x2 1.0 -1.0))))
          (v128.store (local.get $o2) (f64x2.sub (local.get $t0) (local.get $t2)))
          (v128.store (local.get $o3) (f64x2.add (local.get $t1) (f64x2.mul (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $t3) (local.get $t3)) (v128.const f64x2 -1.0 1.0))))
          (local.set $i0 (i32.add (local.get $i0) (i32.const 16)))
          (local.set $i1 (i32.add (local.get $i1) (i32.const 16)))
          (local.set $i2 (i32.add (local.get $i2) (i32.const 16)))
          (local.set $i3 (i32.add (local.get $i3) (i32.const 16)))
          (local.set $o0 (i32.add (local.get $o0) (i32.const 16)))
          (local.set $o1 (i32.add (local.get $o1) (i32.const 16)))
          (local.set $o2 (i32.add (local.get $o2) (i32.const 16)))
          (local.set $o3 (i32.add (local.get $o3) (i32.const 16)))
          (local.set $k (i32.add (local.get $k) (i32.const 1)))
          (br $butterfly_loop)
        ))
        (local.set $i0 (i32.add (local.get $i0) (i32.mul (local.get $r_bytes) (i32.const 3))))
        (local.set $j (i32.add (local.get $j) (i32.const 1)))
        (br $group_loop)
      ))
      (if (i32.eq (local.get $src) (i32.const 0))
        (then (local.set $src (global.get $SECONDARY_OFFSET)) (local.set $dst (i32.const 0)))
        (else (local.set $src (i32.const 0)) (local.set $dst (global.get $SECONDARY_OFFSET))))
      (local.set $r (i32.shr_u (local.get $r) (i32.const 2)))
      (local.set $l (i32.shl (local.get $l) (i32.const 2)))
      (br $stage_loop)
    ))
    (if (i32.ne (local.get $src) (i32.const 0))
      (then
        (local.set $i0 (global.get $SECONDARY_OFFSET))
        (local.set $o0 (i32.const 0))
        (local.set $k (i32.const 0))
        (block $done_copy (loop $copy_loop
          (br_if $done_copy (i32.ge_u (local.get $k) (local.get $n)))
          (v128.store (local.get $o0) (v128.load (local.get $i0)))
          (local.set $i0 (i32.add (local.get $i0) (i32.const 16)))
          (local.set $o0 (i32.add (local.get $o0) (i32.const 16)))
          (local.set $k (i32.add (local.get $k) (i32.const 1)))
          (br $copy_loop)
        ))
      )
    )
  )

  (func $fft_radix4 (param $n i32)
    (if (i32.eq (local.get $n) (i32.const 4)) (then (call $fft_4) (return)))
    (if (i32.eq (local.get $n) (i32.const 16)) (then (call $fft_16) (return)))
    (call $fft_radix4_general (local.get $n))
  )

  ;; ============================================================================
  ;; Radix-2 Stockham: General FFT for N > 4
  ;; ============================================================================
  (func $fft_stockham_general (param $n i32)
    (local $n2 i32) (local $r i32) (local $l i32) (local $j i32) (local $k i32)
    (local $src i32) (local $dst i32) (local $tw_step i32)
    (local $x0 v128) (local $x1 v128) (local $w v128)
    (local $i0 i32) (local $i1 i32) (local $o0 i32) (local $o1 i32)
    (local $r_bytes i32) (local $n2_bytes i32) (local $tw_addr i32)

    (local.set $n2 (i32.shr_u (local.get $n) (i32.const 1)))
    (local.set $n2_bytes (i32.shl (local.get $n2) (i32.const 4)))
    (local.set $src (i32.const 0))
    (local.set $dst (global.get $SECONDARY_OFFSET))
    (local.set $r (local.get $n2))
    (local.set $l (i32.const 1))

    (block $done_stages (loop $stage_loop
      (br_if $done_stages (i32.lt_u (local.get $r) (i32.const 1)))
      (local.set $r_bytes (i32.shl (local.get $r) (i32.const 4)))
      (local.set $tw_step (i32.div_u (local.get $n) (i32.shl (local.get $l) (i32.const 1))))
      (local.set $tw_addr (global.get $TWIDDLE_OFFSET))
      (local.set $j (i32.const 0))
      (local.set $o0 (local.get $dst))
      (local.set $o1 (i32.add (local.get $dst) (local.get $n2_bytes)))
      (local.set $i0 (local.get $src))

      (block $done_groups (loop $group_loop
        (br_if $done_groups (i32.ge_u (local.get $j) (local.get $l)))
        (local.set $w (v128.load (local.get $tw_addr)))
        (local.set $i1 (i32.add (local.get $i0) (local.get $r_bytes)))
        (local.set $k (i32.const 0))

        (block $done_butterflies (loop $butterfly_loop
          (br_if $done_butterflies (i32.ge_u (local.get $k) (local.get $r)))
          (local.set $x0 (v128.load (local.get $i0)))
          (local.set $x1 (v128.load (local.get $i1)))
          (local.set $x1 (call $simd_cmul (local.get $x1) (local.get $w)))
          (v128.store (local.get $o0) (f64x2.add (local.get $x0) (local.get $x1)))
          (v128.store (local.get $o1) (f64x2.sub (local.get $x0) (local.get $x1)))
          (local.set $i0 (i32.add (local.get $i0) (i32.const 16)))
          (local.set $i1 (i32.add (local.get $i1) (i32.const 16)))
          (local.set $o0 (i32.add (local.get $o0) (i32.const 16)))
          (local.set $o1 (i32.add (local.get $o1) (i32.const 16)))
          (local.set $k (i32.add (local.get $k) (i32.const 1)))
          (br $butterfly_loop)
        ))
        (local.set $i0 (i32.add (local.get $i0) (local.get $r_bytes)))
        (local.set $tw_addr (i32.add (local.get $tw_addr) (i32.shl (local.get $tw_step) (i32.const 4))))
        (local.set $j (i32.add (local.get $j) (i32.const 1)))
        (br $group_loop)
      ))
      (if (i32.eq (local.get $src) (i32.const 0))
        (then (local.set $src (global.get $SECONDARY_OFFSET)) (local.set $dst (i32.const 0)))
        (else (local.set $src (i32.const 0)) (local.set $dst (global.get $SECONDARY_OFFSET))))
      (local.set $r (i32.shr_u (local.get $r) (i32.const 1)))
      (local.set $l (i32.shl (local.get $l) (i32.const 1)))
      (br $stage_loop)
    ))
    (if (i32.ne (local.get $src) (i32.const 0))
      (then
        (local.set $i0 (global.get $SECONDARY_OFFSET))
        (local.set $o0 (i32.const 0))
        (local.set $k (i32.const 0))
        (block $done_copy (loop $copy_loop
          (br_if $done_copy (i32.ge_u (local.get $k) (local.get $n)))
          (v128.store (local.get $o0) (v128.load (local.get $i0)))
          (local.set $i0 (i32.add (local.get $i0) (i32.const 16)))
          (local.set $o0 (i32.add (local.get $o0) (i32.const 16)))
          (local.set $k (i32.add (local.get $k) (i32.const 1)))
          (br $copy_loop)
        ))
      )
    )
  )

  (func $fft_stockham (param $n i32)
    (if (i32.eq (local.get $n) (i32.const 4)) (then (call $fft_4) (return)))
    (call $fft_stockham_general (local.get $n))
  )

  ;; Internal FFT dispatcher (uses optimal algorithm based on size)
  ;; NOTE: The fused codelets (fft_32 through fft_1024) output in bit-reversed order,
  ;; which is incompatible with the RFFT post-processing that expects natural order.
  ;; We use the general algorithms (fft_radix4/fft_stockham) which output in natural order.
  ;; TODO: Fix the codelets to output in natural order for better performance.
  (func $fft (param $n i32)
    (if (call $is_power_of_4 (local.get $n))
      (then (call $fft_radix4 (local.get $n)))
      (else (call $fft_stockham (local.get $n)))
    )
  )

  ;; ============================================================================
  ;; Real FFT Twiddle Precomputation
  ;; ============================================================================
  (func $precompute_rfft_twiddles (export "precompute_rfft_twiddles") (param $n i32)
    (local $n2 i32) (local $k i32) (local $angle f64) (local $addr i32) (local $neg_two_pi_over_n f64)
    (local.set $n2 (i32.shr_u (local.get $n) (i32.const 1)))
    ;; Precompute complex FFT twiddles for N/2
    (call $precompute_twiddles (local.get $n2))
    ;; Precompute post-processing twiddles
    (local.set $neg_two_pi_over_n (f64.div (f64.mul (f64.const -2.0) (global.get $PI)) (f64.convert_i32_u (local.get $n))))
    (local.set $k (i32.const 0))
    (block $done (loop $loop
      (br_if $done (i32.gt_u (local.get $k) (local.get $n2)))
      (local.set $angle (f64.mul (f64.convert_i32_u (local.get $k)) (local.get $neg_two_pi_over_n)))
      (local.set $addr (i32.add (global.get $RFFT_TWIDDLE_OFFSET) (i32.shl (local.get $k) (i32.const 4))))
      (f64.store (local.get $addr) (call $cos (local.get $angle)))
      (f64.store (i32.add (local.get $addr) (i32.const 8)) (call $sin (local.get $angle)))
      (local.set $k (i32.add (local.get $k) (i32.const 1)))
      (br $loop)
    ))
  )

  ;; ============================================================================
  ;; Real FFT: N real inputs -> N/2+1 complex outputs
  ;; ============================================================================
  (func $rfft (export "rfft") (param $n i32)
    (local $n2 i32) (local $k i32) (local $k_end i32) (local $n2_minus_k i32)
    (local $zk_re f64) (local $zk_im f64) (local $zn2k_re f64) (local $zn2k_im f64)
    (local $wk_re f64) (local $wk_im f64) (local $wn2k_re f64) (local $wn2k_im f64)
    (local $sum_re f64) (local $sum_im f64) (local $diff_re f64) (local $diff_im f64)
    (local $wd_re f64) (local $wd_im f64)
    (local $sum2_re f64) (local $sum2_im f64) (local $diff2_re f64) (local $diff2_im f64)
    (local $wd2_re f64) (local $wd2_im f64)
    (local $xk_re f64) (local $xk_im f64) (local $xn2k_re f64) (local $xn2k_im f64)
    (local $addr_k i32) (local $addr_n2k i32)
    (local $z0_re f64) (local $z0_im f64)

    ;; Dispatch to fused codelets for small sizes
    (if (i32.eq (local.get $n) (i32.const 8)) (then (call $rfft_8) (return)))
    (if (i32.eq (local.get $n) (i32.const 32)) (then (call $rfft_32) (return)))

    (local.set $n2 (i32.shr_u (local.get $n) (i32.const 1)))

    ;; Run N/2-point FFT (automatically selects radix-4 or radix-2)
    (call $fft (local.get $n2))

    ;; Use SIMD post-processing for N >= 128
    (if (i32.ge_u (local.get $n) (i32.const 128))
      (then
        (call $rfft_postprocess_simd (local.get $n2))
        (return)
      )
    )

    ;; Scalar post-processing for N < 128 (N=16, 64)
    (local.set $z0_re (f64.load (i32.const 0)))
    (local.set $z0_im (f64.load (i32.const 8)))
    (f64.store (i32.const 0) (f64.add (local.get $z0_re) (local.get $z0_im)))
    (f64.store (i32.const 8) (f64.const 0.0))
    (local.set $addr_k (i32.shl (local.get $n2) (i32.const 4)))
    (f64.store (local.get $addr_k) (f64.sub (local.get $z0_re) (local.get $z0_im)))
    (f64.store (i32.add (local.get $addr_k) (i32.const 8)) (f64.const 0.0))

    (local.set $k_end (i32.shr_u (local.get $n2) (i32.const 1)))
    (local.set $k (i32.const 1))
    (block $done_main (loop $main_loop
      (br_if $done_main (i32.ge_u (local.get $k) (local.get $k_end)))
      (local.set $n2_minus_k (i32.sub (local.get $n2) (local.get $k)))
      (local.set $addr_k (i32.shl (local.get $k) (i32.const 4)))
      (local.set $addr_n2k (i32.shl (local.get $n2_minus_k) (i32.const 4)))
      (local.set $zk_re (f64.load (local.get $addr_k)))
      (local.set $zk_im (f64.load (i32.add (local.get $addr_k) (i32.const 8))))
      (local.set $zn2k_re (f64.load (local.get $addr_n2k)))
      (local.set $zn2k_im (f64.load (i32.add (local.get $addr_n2k) (i32.const 8))))
      (local.set $wk_re (f64.load (i32.add (global.get $RFFT_TWIDDLE_OFFSET) (i32.shl (local.get $k) (i32.const 4)))))
      (local.set $wk_im (f64.load (i32.add (global.get $RFFT_TWIDDLE_OFFSET) (i32.add (i32.shl (local.get $k) (i32.const 4)) (i32.const 8)))))
      (local.set $wn2k_re (f64.load (i32.add (global.get $RFFT_TWIDDLE_OFFSET) (i32.shl (local.get $n2_minus_k) (i32.const 4)))))
      (local.set $wn2k_im (f64.load (i32.add (global.get $RFFT_TWIDDLE_OFFSET) (i32.add (i32.shl (local.get $n2_minus_k) (i32.const 4)) (i32.const 8)))))
      ;; X[k]
      (local.set $sum_re (f64.add (local.get $zk_re) (local.get $zn2k_re)))
      (local.set $sum_im (f64.sub (local.get $zk_im) (local.get $zn2k_im)))
      (local.set $diff_re (f64.sub (local.get $zk_re) (local.get $zn2k_re)))
      (local.set $diff_im (f64.add (local.get $zk_im) (local.get $zn2k_im)))
      (local.set $wd_re (f64.add (f64.mul (local.get $wk_im) (local.get $diff_re)) (f64.mul (local.get $wk_re) (local.get $diff_im))))
      (local.set $wd_im (f64.sub (f64.mul (local.get $wk_im) (local.get $diff_im)) (f64.mul (local.get $wk_re) (local.get $diff_re))))
      (local.set $xk_re (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
      (local.set $xk_im (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))
      ;; X[N/2-k]
      (local.set $sum2_re (f64.add (local.get $zn2k_re) (local.get $zk_re)))
      (local.set $sum2_im (f64.sub (local.get $zn2k_im) (local.get $zk_im)))
      (local.set $diff2_re (f64.sub (local.get $zn2k_re) (local.get $zk_re)))
      (local.set $diff2_im (f64.add (local.get $zn2k_im) (local.get $zk_im)))
      (local.set $wd2_re (f64.add (f64.mul (local.get $wn2k_im) (local.get $diff2_re)) (f64.mul (local.get $wn2k_re) (local.get $diff2_im))))
      (local.set $wd2_im (f64.sub (f64.mul (local.get $wn2k_im) (local.get $diff2_im)) (f64.mul (local.get $wn2k_re) (local.get $diff2_re))))
      (local.set $xn2k_re (f64.mul (f64.const 0.5) (f64.add (local.get $sum2_re) (local.get $wd2_re))))
      (local.set $xn2k_im (f64.mul (f64.const 0.5) (f64.add (local.get $sum2_im) (local.get $wd2_im))))
      ;; Store
      (f64.store (local.get $addr_k) (local.get $xk_re))
      (f64.store (i32.add (local.get $addr_k) (i32.const 8)) (local.get $xk_im))
      (f64.store (local.get $addr_n2k) (local.get $xn2k_re))
      (f64.store (i32.add (local.get $addr_n2k) (i32.const 8)) (local.get $xn2k_im))
      (local.set $k (i32.add (local.get $k) (i32.const 1)))
      (br $main_loop)
    ))
    ;; Handle middle element
    (if (i32.and (i32.eqz (i32.and (local.get $n2) (i32.const 1))) (i32.gt_u (local.get $n2) (i32.const 2)))
      (then
        (local.set $addr_k (i32.shl (local.get $k_end) (i32.const 4)))
        (local.set $zk_re (f64.load (local.get $addr_k)))
        (local.set $zk_im (f64.load (i32.add (local.get $addr_k) (i32.const 8))))
        (local.set $wk_re (f64.load (i32.add (global.get $RFFT_TWIDDLE_OFFSET) (i32.shl (local.get $k_end) (i32.const 4)))))
        (local.set $wk_im (f64.load (i32.add (global.get $RFFT_TWIDDLE_OFFSET) (i32.add (i32.shl (local.get $k_end) (i32.const 4)) (i32.const 8)))))
        (local.set $sum_re (f64.mul (f64.const 2.0) (local.get $zk_re)))
        (local.set $sum_im (f64.const 0.0))
        (local.set $diff_re (f64.const 0.0))
        (local.set $diff_im (f64.mul (f64.const 2.0) (local.get $zk_im)))
        (local.set $wd_re (f64.add (f64.mul (local.get $wk_im) (local.get $diff_re)) (f64.mul (local.get $wk_re) (local.get $diff_im))))
        (local.set $wd_im (f64.sub (f64.mul (local.get $wk_im) (local.get $diff_im)) (f64.mul (local.get $wk_re) (local.get $diff_re))))
        (local.set $xk_re (f64.mul (f64.const 0.5) (f64.add (local.get $sum_re) (local.get $wd_re))))
        (local.set $xk_im (f64.mul (f64.const 0.5) (f64.add (local.get $sum_im) (local.get $wd_im))))
        (f64.store (local.get $addr_k) (local.get $xk_re))
        (f64.store (i32.add (local.get $addr_k) (i32.const 8)) (local.get $xk_im))
      )
    )
  )
)
