# FFT Optimization Plan: Closing the Gap with FFTW

## Executive Summary

FFTW-js is ~2x faster than our implementation due to:

1. **Pre-optimized codelets** for sizes 2-64
2. **Hierarchical decomposition** using optimal codelet sizes
3. **FMA (fused multiply-add)** reducing instruction count
4. **Cache-aware memory access** patterns

This document outlines a phased approach to implement these optimizations with proper tooling and testing infrastructure.

---

## Why FFTW-js is Fast: Deep Analysis

FFTW-js is FFTW compiled to WebAssembly via Emscripten, meaning it inherits ALL of FFTW's sophisticated optimizations. Understanding these is key to closing the performance gap.

### 1. The genfft Codelet Generator

FFTW's codelets aren't just unrolled loops - they're generated by a compiler (`genfft`) that:

1. **DAG Representation**: Builds a directed acyclic graph of all operations
2. **Algebraic Simplification**: Applies constant folding, strength reduction, and algebraic identities
3. **Common Subexpression Elimination (CSE)**: Identifies and reuses repeated computations
4. **Network Transposition**: Transposes the computation graph, simplifies, transposes back - this exposes additional common subexpressions invisible to standard CSE
5. **Optimal Scheduling**: Produces a topological sort optimized for register allocation using cache-oblivious theory

**Key insight**: Their codelets have ~10-20% fewer operations than naively unrolled code due to these algebraic optimizations.

### 2. Operation Fusion (Twiddle-Butterfly Fusion)

**What we do**: Separate twiddle multiplication pass + butterfly pass

```
for each k: temp[k] = x[k] * twiddle[k]    // Load twiddle, load x, store temp
for each k: butterfly(temp[k], ...)        // Load temp again
```

**What FFTW does**: Fused twiddle-butterfly kernels

```
for each k: butterfly(x[k] * twiddle[k], ...)  // Load once, compute, store once
```

**Impact**: Eliminates N/2 memory round-trips per stage. For large FFTs, this is huge since memory bandwidth is often the bottleneck.

### 3. Automatic Real-FFT Specialization

FFTW's genfft **automatically derives** optimized real-FFT codelets from complex algorithms by exploiting conjugate symmetry properties. It doesn't just wrap a complex FFT - it generates specialized code that:

- Avoids redundant computation of conjugate pairs
- Uses real-only arithmetic where possible
- Fuses the pack/unpack steps with the FFT computation

### 4. Cache-Oblivious Recursion vs Our Iterative Approach

**Our Stockham**: Iterative, breadth-first - processes all butterflies at each stage before moving to the next

- Good for small FFTs that fit in cache
- Poor locality for large FFTs - data is touched log₂(N) times

**FFTW's approach**: Can use depth-first recursion

- Process subtrees completely before moving on
- Better cache utilization for large FFTs
- Working set stays in cache longer

### 5. The Planner (Less Relevant for WASM)

FFTW's runtime planner measures and selects algorithms. Since fftw-js is pre-compiled, it likely uses fixed plans - but those plans were optimized for the compilation target.

---

## Highest-Impact Optimizations (New Priorities)

Based on the FFTW analysis, these are the optimizations most likely to close the 2x performance gap:

### Priority A: Twiddle-Butterfly Fusion ~~(Expected: +25-40%)~~ **ALREADY IMPLEMENTED**

**Status**: ✅ Already implemented in our code. See Experiment 7.

**Original problem description** (did not apply to our code):

> Our Stockham FFT does separate passes: (1) Apply twiddles (2) Execute butterflies

**Actual implementation**: Our code already fuses twiddle multiply with butterfly in a single loop iteration:

```wat
(local.set $x1 (call $simd_cmul (local.get $x1) (local.get $w)))  ;; twiddle
(v128.store (local.get $o0) (f64x2.add (local.get $x0) (local.get $x1)))  ;; butterfly
(v128.store (local.get $o1) (f64x2.sub (local.get $x0) (local.get $x1)))
```

**Experiment result**: Tried inlining `$simd_cmul` to eliminate function call overhead - no improvement because V8 already inlines small functions.

**Conclusion**: This optimization path is exhausted. No further gains available here.

### Priority B: Fused Real-FFT Codelets ~~(Expected: +20-30% for rfft)~~ **IMPLEMENTED - UP TO +123%**

**Status**: ✅ Implemented for N=8 and N=32. See Experiment 8.

**Current problem**: Our real FFT is a wrapper:

1. Pack real data as complex
2. Run N/2 complex FFT
3. Post-process to extract real spectrum

**Solution**: Generate specialized real-FFT codelets that fuse pack + FFT + unpack.

**Results** (vs fftw-js):
| Size | Before (general) | After (fused codelet) | Improvement vs fftw-js |
| ---- | ---------------- | --------------------- | ---------------------- |
| N=8 | ~20M ops/s | 24.2M ops/s | **+123.8%** |
| N=32 | ~12M ops/s | 13.1M ops/s | **+45.7%** |

**Implementation**:

- `$rfft_8`: Fully fused codelet with inline FFT-4 and hardcoded post-processing twiddles
- `$rfft_32`: Calls `$fft_16` codelet then does hardcoded post-processing (eliminates twiddle memory loads)

### Priority C: DAG-Based Codelet Optimization (Expected: +10-20% for codelets)

**Current approach**: Manually write or naively unroll FFT code

**Solution**: Build a simple codelet generator that:

1. Constructs operation DAG from FFT algorithm
2. Applies CSE (common subexpression elimination)
3. Schedules for register pressure
4. Emits optimized WAT

**Key CSE opportunities in FFT**:

- Twiddle factors: `W_N^k` and `W_N^{N-k}` are conjugates
- Butterfly symmetry: `a+b` and `a-b` share the same inputs
- Real-data symmetry: Exploits conjugate pairs

**Implementation**:

```javascript
// tools/codelet_generator.js
class FFTCodeletGenerator {
  buildDAG(size, algorithm) {
    /* DIT or DIF Cooley-Tukey */
  }
  applyCSE(dag) {
    /* Hash-based common subexpression elimination */
  }
  schedule(dag) {
    /* Topological sort minimizing live variables */
  }
  emitWAT(scheduled) {
    /* Generate WAT with local variables */
  }
}
```

### Priority D: Depth-First Recursive FFT (Expected: +15-25% for N ≥ 1024)

**Current approach**: Iterative Stockham (breadth-first)

- Processes all N/2 butterflies at stage 1, then all at stage 2, etc.
- For N=4096: Touches all 4096 elements 12 times (log₂N stages)

**Solution**: Recursive decomposition with codelet base cases

```
fft(x, N):
  if N <= 64:
    codelet_N(x)  // Fully unrolled, fits in registers
  else:
    fft(x_even, N/2)     // Complete left subtree
    fft(x_odd, N/2)      // Complete right subtree
    combine(x, N)        // Single pass butterfly
```

**Benefits**:

- Working set of N/2 stays hot in cache during recursion
- Better temporal locality
- Naturally composable with codelets

**Challenges**:

- WebAssembly call overhead (mitigate with larger codelet base cases)
- Stack usage (mitigate with explicit stack or tail calls)

**Implementation**:

1. Create `modules/fft_recursive.wat`
2. Use codelets for N ≤ 64
3. Benchmark crossover point where recursive beats iterative

### Priority E: Register-Aware Scheduling (Expected: +5-10%)

**Problem**: WASM has unlimited locals, but V8/SpiderMonkey map to limited registers. Poor scheduling causes register spills.

**Solution**: Schedule operations to minimize live variables at any point.

**Heuristic** (from FFTW paper):

1. Build dependency DAG
2. Use "Sethi-Ullman" style numbering
3. Execute operations in order that minimizes max simultaneous live values

**Target**: Keep live values ≤ 16 (typical register file size)

### Priority F: Hierarchical Small-Codelet Composition (Expected: +10-20%) **IMPLEMENTED - LIMIT REACHED**

**Status**: ✅ Implemented for N=32, N=64, N=128, N=256, N=512, and N=1024. **N=1024 is the optimal ceiling** - extending to N=2048 made performance worse.

**Problem**: Large monolithic codelets (N≥32) have too many locals causing register spills (see Experiment 6).

**Solution**: Use small codelets (N=4, N=16) as building blocks and compose them using DIF decomposition.

**Implemented**:

- `$fft_32`: DIF decomposition using two `$fft_16_at` calls
- `$fft_64`: DIF decomposition using two `$fft_32_at` calls
- `$fft_128`: DIF decomposition using two `$fft_64_at` calls
- `$fft_256`: DIF decomposition using two `$fft_128_at` calls
- `$fft_512`: DIF decomposition using two `$fft_256_at` calls
- `$fft_1024`: DIF decomposition using two `$fft_512_at` calls (optimal limit)

```
fft_1024:
  // First pass: butterflies with W_1024^k twiddles
  for k in 0..511:
    first_half[k] = x[k] + x[k+512]
    second_half[k] = (x[k] - x[k+512]) * W_1024^k

  fft_512_at(0)     // First half
  fft_512_at(8192)  // Second half (512 * 16 bytes)
```

**Results**:

- N=64: improved from -30% to **+3.4%** vs fftw-js
- N=128: improved from -33% to **-16.8%** vs fftw-js
- N=256: improved from -17% to **+12.3%** vs fftw-js
- N=512: improved from -21% to **-15.8%** vs fftw-js
- N=1024: improved from -40% to **-26.9%** vs fftw-js
- N=2048: improved from -33% to **-31.1%** vs fftw-js (minimal gain - fft(1024) already used $fft_1024)

**Benefits**:

- Each codelet stays within register limits
- Reuses proven, optimized small codelets
- Hardcoded twiddles eliminate memory loads

**Limitations discovered**:

- ❌ Extending to `$fft_2048` made N=4096 **7% slower** due to instruction cache thrashing
- The optimal cutoff is **N=1024** - beyond this, simple loops beat hierarchical composition
- Code size grows exponentially: $fft_2048 alone would add 13,800 lines of WAT

### Priority G: Real-Only Arithmetic in Early Stages (Expected: +5-15% for rfft)

**Problem**: rfft input is purely real, but we treat it as complex from the start.

**Solution**: Exploit real-only input in early FFT stages where imaginary parts are known to be zero.

```wat
;; Stage 1 of rfft: input is real, imaginary = 0
;; Butterfly: (a + 0i) ± (b + 0i) * W
;; Can skip all imaginary multiplications in first stage
```

**Implementation**:

1. Create specialized first-stage butterfly that assumes im=0
2. Transition to full complex arithmetic after first stage
3. May require separate code paths (size vs complexity tradeoff)

### Priority H: SIMD Pack/Unpack Fusion (Expected: +5-10% for rfft)

**Problem**: rfft pack step `z[k] = x[2k] + i*x[2k+1]` is a separate loop.

**Solution**: Use SIMD shuffles to pack 2 complex values simultaneously.

```wat
;; Current: scalar pack loop
;; Proposed: SIMD pack
(v128.load (i32.const 0))           ;; [x0, x1, x2, x3]
(i8x16.shuffle ...)                  ;; Rearrange to [x0, x1] [x2, x3] as 2 complex
```

**Note**: May also fuse with first butterfly stage for additional gains.

---

## Optimization Experiment Log

### Experiment 1: Dual-Complex f32 SIMD (2026-01-21)

**Hypothesis**: Process 2 f32 complex numbers per v128 register instead of 1, doubling SIMD throughput.

**Implementation**:

- Added `$simd_cmul_f32_dual` function for dual-complex multiply
- Modified butterfly loop to process pairs when r >= 2
- Added twiddle replication: `[w.re, w.im]` → `[w.re, w.im, w.re, w.im]`

**Result**: **FAILURE - 15-20% SLOWER**

| Size   | Before     | After      | Change |
| ------ | ---------- | ---------- | ------ |
| N=64   | 4.6M ops/s | 3.9M ops/s | -15%   |
| N=256  | 1.1M ops/s | 0.9M ops/s | -20%   |
| N=1024 | 249K ops/s | 203K ops/s | -18%   |
| N=4096 | 55K ops/s  | 46K ops/s  | -15%   |

**Analysis**: The overhead outweighed the benefits:

1. **Branch overhead**: `if (r >= 2)` check added to every group iteration
2. **Twiddle replication**: Extra shuffle instruction per group
3. **JIT interference**: More complex control flow may have prevented V8 optimizations
4. **Most work in r=1 stages**: For later stages (where l is large), r=1 and dual-complex doesn't help

**Lesson**: Simple, predictable loops optimize better than clever branching. The JIT compiler is already good at vectorization when the loop is simple.

### Experiment 2: N=8 Codelet (2026-01-21)

**Hypothesis**: Fully unrolled N=8 kernel with inline twiddles eliminates loop overhead and twiddle lookups.

**Implementation**: Attempted 3-stage unrolled kernel with hardcoded W_8^k twiddles.

**Result**: **FAILURE - Incorrect output**

**Analysis**: The Stockham FFT has complex permutation semantics:

1. Each stage reorders data differently than standard Cooley-Tukey DIT
2. The ping-pong buffer swap changes which indices map to which variables
3. Output positions after each stage are non-intuitive

**Lesson**: Codelet generation should be automated, not hand-written. A codelet generator that traces the actual algorithm would avoid these errors. This is exactly why FFTW uses `genfft`.

### Experiment 3: Radix-4 Stockham with SIMD (2026-01-21)

**Hypothesis**: Radix-4 algorithm has 50% fewer stages than radix-2 (log₄(N) vs log₂(N)), reducing memory passes. Combined with SIMD, should significantly improve throughput.

**Implementation**:

- Created `modules/fft_radix4.wat` with radix-4 Stockham algorithm
- SIMD N=4 kernel using v128 for butterfly operations
- Inlined SIMD complex multiply in the main butterfly loop
- Twiddles loaded as v128 [re, im] pairs
- Butterfly outputs computed with SIMD add/sub and shuffle for ±j multiplication

**Result**: **SUCCESS - Up to +51.3% faster than radix-2**

| Size   | Radix-2 (ops/s) | Radix-4 SIMD (ops/s) | Speedup                |
| ------ | --------------- | -------------------- | ---------------------- |
| N=4    | 24.3M           | 21.4M                | -11.9% (SIMD overhead) |
| N=16   | 10.4M           | 12.2M                | **+16.9%**             |
| N=64   | 3.5M            | 3.9M                 | **+10.5%**             |
| N=256  | 797K            | 977K                 | **+22.6%**             |
| N=1024 | 169K            | 196K                 | **+16.3%**             |
| N=4096 | 29.5K           | 44.6K                | **+51.3%**             |

**Analysis**:

1. **Stage reduction pays off**: log₄(4096) = 6 stages vs log₂(4096) = 12 stages
2. **SIMD inlining critical**: Initial version with function call overhead for `$simd_cmul` was 25-40% _slower_ than radix-2
3. **Large sizes benefit most**: Cache pressure reduction from fewer stages has compounding effect
4. **N=4 slower**: Fixed SIMD overhead dominates at tiny sizes; could special-case with scalar

**Key code pattern** (inlined SIMD complex multiply):

```wat
;; b1 = b * w1 (inlined, no function call)
(local.set $b1
  (f64x2.add
    (f64x2.mul (local.get $b)
      (i8x16.shuffle 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 (local.get $w1) (local.get $w1)))
    (f64x2.mul
      (f64x2.mul
        (i8x16.shuffle 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 (local.get $b) (local.get $b))
        (i8x16.shuffle 8 9 10 11 12 13 14 15 8 9 10 11 12 13 14 15 (local.get $w1) (local.get $w1)))
      (v128.const f64x2 -1.0 1.0))))
```

**Files created**:

- `modules/fft_radix4.wat` - Radix-4 Stockham with SIMD
- `tests/radix4.test.js` - Correctness tests
- `benchmarks/radix4.bench.js` - Performance benchmarks

### Current Performance (Final Benchmark Results)

Comparison against fft.js (best pure JS library, Radix-4 by Fedor Indutny):

| Size   | wat-fft Radix-2 | wat-fft Radix-4 | fft.js      | Radix-4 vs fft.js |
| ------ | --------------- | --------------- | ----------- | ----------------- |
| N=16   | 11.1M ops/s     | **12.2M ops/s** | 11.4M ops/s | **+7%**           |
| N=64   | 3.4M ops/s      | **3.8M ops/s**  | 2.8M ops/s  | **+37%**          |
| N=256  | 791K ops/s      | **971K ops/s**  | 561K ops/s  | **+73%**          |
| N=1024 | 166K ops/s      | **195K ops/s**  | 113K ops/s  | **+72%**          |
| N=4096 | 29.6K ops/s     | **44K ops/s**   | 23.5K ops/s | **+87%**          |

**Result**: Our Radix-4 SIMD implementation is now the fastest FFT across all tested sizes, outperforming even the best pure JS implementations by 7-87% depending on size.

Note: The original comparison target was fftw-js (FFTW via Emscripten). The numbers above use fft.js as the JS baseline. FFTW-js would likely still be faster at larger sizes due to its sophisticated codelet system and cache-oblivious algorithms.

### Experiment 4: N=16 Fully Unrolled Codelet (2026-01-21)

**Hypothesis**: Fully unrolled N=16 codelet with inline twiddle constants eliminates all loop overhead and twiddle lookups.

**Implementation**:

- Added `$fft_16` function with all 16 loads, 2 radix-4 stages fully unrolled
- Inline twiddle constants: W_16^1 through W_16^9
- No loops, no twiddle table lookups

**Result**: **SUCCESS - +54.6% speedup at N=16**

| Size | Before N=16 Codelet           | After N=16 Codelet | Improvement           |
| ---- | ----------------------------- | ------------------ | --------------------- |
| N=16 | 12.2M ops/s (+17% vs radix-2) | 16.5M ops/s        | **+54.6%** vs radix-2 |

### Experiment 5: Real FFT with Radix-4 (2026-01-21)

**Implementation**: Created `fft_real_radix4.wat` combining radix-4 complex FFT with real FFT post-processing.

**Result**: **SUCCESS** - All tests pass, provides faster rfft for power-of-4 N/2 sizes.

### Experiment 6: Automated Codelet Generator (2026-01-22)

**Hypothesis**: An automated codelet generator using DAG-based symbolic tracing with CSE would produce correct, optimized codelets for any size.

**Implementation**:

- Created `tools/codelet_generator.js` with:
  - Symbolic expression system (`Expr` class with hash-based CSE)
  - `StockhamTracer` that traces the FFT algorithm symbolically
  - `SIMDWATGenerator` that emits optimized WAT with SIMD v128 operations
  - Support for both radix-2 and radix-4 algorithms
- Generated N=32 (radix-2) and N=64 (radix-4) codelets
- Integrated into `fft_combined.wat` with dispatch logic

**Result**: **PARTIAL SUCCESS - Correct but limited performance gains**

| Size | Standalone codelet vs general loop | rfft benchmark vs fftw-js |
| ---- | ---------------------------------- | ------------------------- |
| N=32 | +15.6% faster                      | rfft(64): -32.0%          |
| N=64 | +18.9% faster                      | rfft(128): -33.4%         |

**Analysis**:

1. **Codelets are numerically correct** - Max error ~10⁻¹⁵ (machine precision)
2. **Too many locals cause register spilling**:
   - N=32 codelet: 320+ locals (32 inputs + 288 temps)
   - N=64 codelet: 768+ locals (64 inputs + 704 temps)
   - WebAssembly engines spill excess locals to stack memory
3. **General SIMD loop already efficient** - The Stockham loop with inlined SIMD complex multiply is competitive; codelet overhead (spills) may negate unrolling benefits
4. **Hand-written $fft_16 still wins** - Only ~20 locals, carefully optimized, used by rfft(32) which beats fftw-js by +43%

**Key Insight**: FFTW's approach of composing **small** codelets (N≤16) hierarchically is superior to generating **large** monolithic codelets. Large unrolled codelets exhaust registers and cause spills.

**Lesson**: Future work should focus on:

- Keeping codelets small (N≤16)
- Using hierarchical composition for larger sizes
- Register-aware scheduling to minimize live variables

**Files created/modified**:

- `tools/codelet_generator.js` - Automated codelet generator
- `modules/fft_combined.wat` - Added $fft_32, $fft_64 codelets and dispatch

### Experiment 7: Inline SIMD Complex Multiply (2026-01-22)

**Hypothesis**: The radix-2 Stockham code uses `call $simd_cmul` while radix-4 inlines the complex multiply. Inlining should eliminate function call overhead.

**Implementation**:

- Replaced `(call $simd_cmul (local.get $x1) (local.get $w))` with inline SIMD operations
- Used same pattern as radix-4: shuffle + multiply + sign flip

**Result**: **NO IMPROVEMENT - V8 already inlines small functions**

| Size (radix-2) | Before (function call) | After (inlined) | Change |
| -------------- | ---------------------- | --------------- | ------ |
| N=32           | 6.15M ops/s            | 6.15M ops/s     | ~0%    |
| N=128          | 1.59M ops/s            | 1.59M ops/s     | ~0%    |
| N=512          | 346K ops/s             | 346K ops/s      | ~0%    |

**Analysis**:

1. **V8's TurboFan JIT already inlines** small hot functions like `$simd_cmul`
2. **Code was already fused** - twiddle multiply and butterfly were in the same loop, no intermediate memory stores
3. **The optimization plan's description was outdated** - it described "separate passes" but our code never did that

**Key Insight**: The "twiddle-butterfly fusion" optimization (Priority A, expected +25-40%) doesn't apply to our implementation because we already have them fused. The description in the plan was based on a different code pattern.

**Lesson**: Modern JIT compilers are very good at inlining. Manual inlining for small functions rarely helps and reduces code readability.

### Experiment 8: Fused Real-FFT Codelets (2026-01-22)

**Hypothesis**: Creating specialized rfft codelets that fuse the FFT computation with hardcoded post-processing twiddles will eliminate memory loads and function call overhead.

**Implementation**:

1. **`$rfft_8`**: Fully fused codelet
   - Inline FFT-4 butterfly operations
   - Hardcoded post-processing twiddles (W_8^k constants)
   - Outputs: DC, Nyquist, X[1], X[2], X[3] with no memory loads for twiddles

2. **`$rfft_32`**: Hybrid approach
   - Calls existing `$fft_16` codelet (already optimized)
   - Hardcoded post-processing with inline twiddle constants
   - Processes k=1..7 pairs plus middle element with no twiddle memory loads

**Results**: **SIGNIFICANT IMPROVEMENT**

| Size | wat-fft before | wat-fft after | fftw-js (f32) | vs fftw-js  |
| ---- | -------------- | ------------- | ------------- | ----------- |
| N=8  | 20.5M ops/s    | 24.2M ops/s   | 10.8M ops/s   | **+123.8%** |
| N=32 | 12.0M ops/s    | 13.1M ops/s   | 9.0M ops/s    | **+45.7%**  |

**Analysis**:

1. **For N=8**, the fused codelet eliminates:
   - Function call to `$fft` (4-point FFT)
   - All twiddle memory loads in post-processing
   - Loop overhead in post-processing

2. **For N=32**, the hybrid approach:
   - Keeps the well-optimized `$fft_16` codelet (avoids code duplication)
   - Eliminates 7 twiddle memory loads per pair (14 total) + middle element

3. **Diminishing returns for larger sizes**:
   - FFT computation dominates for N≥64
   - Post-processing overhead becomes proportionally smaller
   - Full fusion would require too many locals (register pressure)

**Key Insight**: For small sizes (N≤32), the overhead of memory loads and function calls is proportionally significant. Fusing these operations with hardcoded constants provides substantial speedups without register pressure issues.

### Experiment 9: Hierarchical FFT Composition (2026-01-23)

**Hypothesis**: Building larger FFTs from smaller optimized codelets (hierarchical composition) would avoid the slow radix-2 Stockham path for non-power-of-4 sizes.

**Problem**: rfft(64) calls fft(32) internally, but 32 is NOT a power of 4 (2^5), so it was using radix-2 Stockham with 5 stages instead of the faster radix-4. Similarly, rfft(128) calls fft(64), and rfft(256) calls fft(128).

**Solution**: Use DIF (Decimation in Frequency) decomposition to build larger FFTs hierarchically:

1. **`$fft_32`**: Implemented using two `$fft_16_at` calls
   - First pass: 16 butterflies combining x[k] and x[k+16] with hardcoded W_32^k twiddles
   - Then two independent FFT-16 calls on each half

2. **`$fft_64`**: Implemented using two `$fft_32_at` calls
   - First pass: 32 butterflies combining x[k] and x[k+32] with hardcoded W_64^k twiddles
   - Then two independent FFT-32 calls on each half

3. **`$fft_128`**: Implemented using two `$fft_64_at` calls
   - First pass: 64 butterflies combining x[k] and x[k+64] with hardcoded W_128^k twiddles
   - Then two independent FFT-64 calls on each half

4. **`$fft_256`**: Implemented using two `$fft_128_at` calls
   - First pass: 128 butterflies combining x[k] and x[k+128] with hardcoded W_256^k twiddles
   - Then two independent FFT-128 calls on each half

5. **`$fft_512`**: Implemented using two `$fft_256_at` calls
   - First pass: 256 butterflies combining x[k] and x[k+256] with hardcoded W_512^k twiddles
   - Then two independent FFT-256 calls on each half

6. **`$fft_1024`**: Implemented using two `$fft_512_at` calls
   - First pass: 512 butterflies combining x[k] and x[k+512] with hardcoded W_1024^k twiddles
   - Then two independent FFT-512 calls on each half

7. **Parameterized codelets** (`$fft_16_at`, `$fft_32_at`, `$fft_64_at`, `$fft_128_at`, `$fft_256_at`, `$fft_512_at`): Take a base offset parameter to operate at arbitrary memory locations, enabling composition.

**Implementation Pattern** (DIF decomposition):

```wat
(func $fft_N
  ;; First pass: for each k, compute:
  ;;   first_half[k] = x[k] + x[k+N/2]
  ;;   second_half[k] = (x[k] - x[k+N/2]) * W_N^k

  ;; k=0: W_N^0 = (1, 0) - no multiply needed
  (local.set $a (v128.load (i32.const 0)))
  (local.set $b (v128.load (i32.const N/2*16)))  ;; offset = N/2 * 16 bytes
  (v128.store (i32.const 0) (f64x2.add (local.get $a) (local.get $b)))
  (v128.store (i32.const N/2*16) (f64x2.sub (local.get $a) (local.get $b)))

  ;; k=1..N/2-1: apply hardcoded W_N^k twiddles using SIMD complex multiply
  ;; ...

  ;; Then run FFT-N/2 on each half
  (call $fft_N/2_at (i32.const 0))
  (call $fft_N/2_at (i32.const N/2*16))
)
```

**Results**: **SIGNIFICANT IMPROVEMENT for N=64, N=128, N=256, N=512, N=1024, and N=2048**

| Size   | Before (radix-2)   | After (hierarchical) | vs fftw-js |
| ------ | ------------------ | -------------------- | ---------- |
| N=64   | 4.8M ops/s (-30%)  | 6.9M ops/s           | **+3.4%**  |
| N=128  | 2.9M ops/s (-33%)  | 3.5M ops/s           | **-16.8%** |
| N=256  | 1.2M ops/s (-17%)  | 1.7M ops/s           | **+12.3%** |
| N=512  | 0.7M ops/s (-21%)  | 0.76M ops/s          | **-15.8%** |
| N=1024 | 0.27M ops/s (-40%) | 0.34M ops/s          | **-26.9%** |
| N=2048 | 0.14M ops/s (-33%) | 0.14M ops/s          | **-31.1%** |

**Analysis**:

1. **N=64 now beats fftw-js**: By using hierarchical fft_32 (composed of two fft_16), we avoid the slow 5-stage radix-2 Stockham entirely
2. **N=128 improved by ~17 percentage points**: rfft(128) calls fft(64), which now uses hierarchical composition
3. **N=256 improved by ~30 percentage points**: rfft(256) calls fft(128), which now uses hierarchical composition - now **beats fftw-js by +12%**
4. **N=512 improved by ~5 percentage points**: rfft(512) calls fft(256), which now uses hierarchical $fft_256 composition
5. **N=1024 improved by ~13 percentage points**: rfft(1024) calls fft(512), which now uses hierarchical $fft_512 composition
6. **N=2048 improved by ~2 percentage points**: rfft(2048) calls fft(1024), which now uses hierarchical $fft_1024 composition
7. **Hardcoded twiddles**: All W_N^k twiddles are inline constants, eliminating memory loads
8. **Low register pressure**: Each sub-FFT codelet operates independently, avoiding register spills

**Key Insight**: FFTW's approach of using small codelets (N≤16) as building blocks works well in WebAssembly. The hierarchical composition avoids register pressure issues while still benefiting from fully-optimized small codelets.

**Files modified**:

- `modules/fft_real_combined.wat` - Added `$fft_16_at`, `$fft_32`, `$fft_32_at`, `$fft_64`, `$fft_64_at`, `$fft_128`, `$fft_128_at`, `$fft_256`, `$fft_256_at`, `$fft_512`, `$fft_512_at`, `$fft_1024`, updated `$fft` dispatch

### Final Performance Summary (2026-01-23)

After all optimizations, wat-fft Combined achieves:

**Complex FFT (vs fft.js pure JS):**
| Size | wat-fft Combined | fft.js (best JS) | Speedup |
| ------ | ---------------- | ---------------- | -------- |
| N=16 | 16.1M ops/s | 11.0M ops/s | **+46%** |
| N=64 | 3.8M ops/s | 2.7M ops/s | **+41%** |
| N=256 | 967K ops/s | 554K ops/s | **+75%** |
| N=1024 | 186K ops/s | 109K ops/s | **+71%** |
| N=4096 | 42.8K ops/s | 22.7K ops/s | **+89%** |

**Real FFT (vs fftw-js Emscripten/FFTW):**
| Size | wat-fft Combined | fftw-js (f32) | vs fftw-js |
| ----- | ---------------- | ------------- | ----------- |
| N=8 | 23.6M ops/s | 10.4M ops/s | **+126.1%** |
| N=16 | 12.1M ops/s | 10.0M ops/s | **+22.4%** |
| N=32 | 12.8M ops/s | 9.0M ops/s | **+43.3%** |
| N=64 | 6.9M ops/s | 6.6M ops/s | **+3.4%** |
| N=128 | 3.5M ops/s | 4.2M ops/s | -16.8% |
| N=256 | 1.7M ops/s | 1.5M ops/s | **+12.3%** |
| N=512 | 757K ops/s | 900K ops/s | -15.8% |
| N=1024 | 336K ops/s | 460K ops/s | -26.9% |
| N=2048 | 142K ops/s | 206K ops/s | -31.1% |
| N=4096 | 59K ops/s | 106K ops/s | -44.2% |

**Conclusion**:

- Fused rfft codelets (`$rfft_8`, `$rfft_32`) provide **massive speedups for small sizes**
- For N≤64 and N=256, we now **beat fftw-js** (Emscripten port of FFTW)
- Hierarchical FFT composition (`$fft_32`, `$fft_64`, `$fft_128`, `$fft_256`, `$fft_512`, `$fft_1024`) provides consistent speedups
- For N=128 and N≥512, fftw-js still has an advantage but the gap is narrowing

**Key findings from codelet generator experiment (2026-01-22)**:

- Automated codelet generation works and produces correct code
- However, large codelets (N≥32) have too many locals causing register spills
- Small hand-written codelets (N≤16) outperform generated large codelets
- Fused rfft codelets with hardcoded twiddles are very effective for small N

**Key findings from fused rfft experiment (2026-01-22)**:

- Fusing FFT + post-processing eliminates significant overhead for small N
- For N=8: eliminating all function calls and twiddle loads gives +123% vs fftw-js
- For N=32: hybrid approach (call fft_16 + hardcoded post-processing) gives +46% vs fftw-js
- Diminishing returns for N≥64 as FFT computation dominates

**Key findings from hierarchical composition experiment (2026-01-23)**:

- DIF decomposition with parameterized codelets (`$fft_16_at`, `$fft_32_at`, `$fft_64_at`, `$fft_128_at`, `$fft_256_at`, `$fft_512_at`) enables hierarchical composition
- `$fft_32` (2x fft_16), `$fft_64` (2x fft_32), `$fft_128` (2x fft_64), `$fft_256` (2x fft_128), `$fft_512` (2x fft_256), and `$fft_1024` (2x fft_512) avoid slow radix-2 path
- N=64 improved from -30% to **+3.4%** vs fftw-js
- N=128 improved from -33% to **-16.8%** vs fftw-js
- N=256 improved from -17% to **+12.3%** vs fftw-js (rfft(256) calls fft(128) internally)
- N=512 improved from -21% to **-15.8%** vs fftw-js (rfft(512) calls fft(256) internally)
- N=1024 improved from -40% to **-26.9%** vs fftw-js (rfft(1024) calls fft(512) internally)
- N=2048 improved from -33% to **-31.1%** vs fftw-js (rfft(2048) calls fft(1024) internally)

**Failed experiment: $fft_2048 hierarchical composition (2026-01-23)**:

Attempted to extend hierarchical composition to N=2048 to improve rfft(4096) performance. The implementation was correct but **made performance worse**:

- N=4096: went from **-44%** to **-51%** vs fftw-js (7 percentage points worse)

**Why $fft_2048 failed**:

| Factor        | Impact                                                           |
| ------------- | ---------------------------------------------------------------- |
| Code size     | 13,800 lines of WAT → instruction cache thrashing                |
| Call depth    | 8 levels deep: `$fft_2048` → `$fft_1024_at` → ... → `$fft_16_at` |
| Twiddle bloat | 1024 inline twiddle constants in just the first pass             |

**The crossover point**: Hierarchical composition is beneficial when:

- Small codelets fit in instruction cache
- Function call overhead < loop overhead saved
- Twiddle inline savings > code bloat cost

For N≥2048, the simple radix-2/radix-4 Stockham loops are more efficient because:

- Compact, cache-friendly code
- Modern CPUs predict simple loops well
- Twiddle table lookups are fast when data is hot in cache

**Conclusion**: The hierarchical approach has **diminishing returns** and becomes **counterproductive** at N≥2048. The optimal cutoff for hierarchical codelets is around N=1024.

Further gains for large N would require fundamentally different approaches:

- Cache-oblivious recursive algorithms (not just hierarchical codelets)
- Runtime planning (like FFTW's planner) to select algorithms per-size
- Depth-first recursion with explicit stack management to improve cache locality

---

## Phase 1: Testing & Benchmarking Infrastructure

### 1.1 Correctness Test Suite

Before optimizing, we need robust correctness tests that will catch regressions.

**Tests to create:**

- [ ] Property-based tests for all FFT sizes (2-8192)
- [ ] Round-trip tests: `ifft(fft(x)) ≈ x`
- [ ] Parseval's theorem: `sum(|x|²) = sum(|X|²)/N`
- [ ] Known-value tests (impulse, sine waves, DC)
- [ ] Linearity: `fft(ax + by) = a*fft(x) + b*fft(y)`
- [ ] Shift theorem: time shift = phase rotation in frequency
- [ ] Comparison against reference implementation (fft.js)

**File:** `tests/fft.correctness.test.js`

### 1.2 Performance Regression Suite

Automated benchmarks that run on every change.

**Metrics to track:**

- ops/sec for each size (64, 256, 1024, 4096)
- Memory bandwidth utilization
- Cache miss rates (if measurable)
- Comparison vs baseline and competitors

**File:** `benchmarks/regression.bench.js`

### 1.3 Profiling Tools

**Tools to create:**

- [ ] Instruction count analyzer (count WASM ops)
- [ ] Memory access pattern visualizer
- [ ] Twiddle factor reuse analyzer
- [ ] Butterfly operation counter

**File:** `tools/profiler.js`

---

## Phase 2: Codelet Generation System

### 2.1 Codelet Generator

Create a tool that generates optimal WAT code for small FFT sizes.

**Approach:**

```
Input: FFT size N (2, 4, 8, 16, 32, 64)
Output: Optimized WAT function for that size
```

**Optimizations to apply:**

1. Eliminate all loops (fully unrolled)
2. Precompute all twiddle factors as constants
3. Minimize temporary variables
4. Reorder operations for instruction pipelining
5. Use FMA where beneficial

**Example output for N=8:**

```wat
(func $fft8 (param $base i32)
  ;; All 8 inputs loaded, all butterflies unrolled
  ;; Twiddles are inline constants
  ;; ~56 adds, ~24 muls for complex 8-point FFT
)
```

**File:** `tools/codelet_generator.js`

### 2.2 Codelet Sizes to Generate

| Size | Radix | Multiplications | Additions | Priority |
| ---- | ----- | --------------- | --------- | -------- |
| 2    | 2     | 0               | 4         | High     |
| 4    | 4     | 0               | 16        | High     |
| 8    | 2×4   | 4               | 52        | High     |
| 16   | 4×4   | 24              | 148       | High     |
| 32   | 2×16  | 88              | 388       | Medium   |
| 64   | 4×16  | 264             | 964       | Medium   |

### 2.3 Codelet Verification

Each generated codelet must pass:

- [ ] Correctness test against reference
- [ ] Performance test (must beat generic loop)
- [ ] Code size check (not too large)

**File:** `tests/codelet.test.js`

---

## Phase 3: Algorithm Improvements

### 3.1 Split-Radix Algorithm

Current: Pure radix-2 (1 butterfly type)
Target: Split-radix (mixed radix-2 and radix-4)

**Benefits:**

- ~33% fewer multiplications than radix-2
- Better instruction-level parallelism

**Implementation steps:**

1. [ ] Implement radix-4 butterfly
2. [ ] Implement split-radix decomposition
3. [ ] Create hybrid that uses radix-4 when N is divisible by 4

**Theoretical improvement:** ~20% faster

### 3.2 Radix-4 Stockham

Pure radix-4 for power-of-4 sizes (4, 16, 64, 256, 1024, 4096).

**Benefits:**

- Twiddles W_N^0 = 1, W_N^(N/4) = -i are trivial
- 25% fewer stages than radix-2
- Better for SIMD (4-way operations)

**File:** `modules/fft_stockham_radix4.wat`

### 3.3 Mixed-Radix Support

For sizes like 12, 24, 48 (products of 2, 3, 4):

- Radix-2 kernel
- Radix-3 kernel
- Radix-4 kernel
- Combine hierarchically

---

## Phase 4: Memory Optimization

### 4.1 Cache-Oblivious Recursion

Instead of iterative stages, use recursive decomposition that naturally fits cache.

```
fft(x, n):
  if n <= CACHE_THRESHOLD:
    use_codelet(x, n)
  else:
    fft(even, n/2)
    fft(odd, n/2)
    combine(even, odd, n)
```

### 4.2 Twiddle Factor Optimization

Current: Precompute all N/2 twiddles
Better:

- Sizes ≤64: inline constants in codelets
- Sizes >64: compute on-the-fly with recurrence

**Twiddle recurrence:**

```
W[k+1] = W[k] * W[1]  (one complex multiply)
```

### 4.3 In-Place vs Out-of-Place

Analyze when in-place (Gentleman-Sande DIF) is better than out-of-place (Stockham).

---

## Phase 5: SIMD Deep Optimization

### 5.1 f32x4 Dual-Complex Operations

Pack 2 complex f32 numbers per v128 register.

**Current:** 1 complex per SIMD op
**Target:** 2 complex per SIMD op (requires algorithm restructuring)

### 5.2 Radix-4 SIMD Butterfly

A radix-4 butterfly naturally processes 4 values, perfect for f32x4.

```wat
;; Process 4 complex values in 2 v128 registers
;; Input: [x0, x1] [x2, x3] as v128 pairs
;; Output: [X0, X1] [X2, X3] with full SIMD utilization
```

### 5.3 Memory Coalescing

Ensure consecutive memory accesses for SIMD loads/stores.

---

## Tooling To Build

### Tool 1: Codelet Generator (`tools/codelet_generator.js`)

```javascript
// Usage: node tools/codelet_generator.js --size 8 --radix 2 --output modules/codelets/
// Generates: fft8.wat with fully unrolled, optimized code

class CodeletGenerator {
  generateFFT(size, options) { ... }
  optimizeForFMA(ast) { ... }
  reorderForPipelining(ast) { ... }
  emitWAT(ast) { ... }
}
```

### Tool 2: Performance Comparator (`tools/perf_compare.js`)

```javascript
// Usage: node tools/perf_compare.js --baseline main --candidate feature-branch
// Output: Performance diff table with statistical significance

async function comparePerformance(baseline, candidate, sizes) {
  // Run both, compute confidence intervals
  // Report: "N=1024: +15% ± 2% (p < 0.01)"
}
```

### Tool 3: Operation Counter (`tools/op_counter.js`)

```javascript
// Usage: node tools/op_counter.js modules/fft_stockham.wat
// Output:
//   f64.mul: 1,234
//   f64.add: 2,345
//   v128.load: 567
//   Total ops per butterfly: 12.3

function countOperations(watFile) {
  // Parse WAT, count by opcode type
}
```

### Tool 4: Memory Access Analyzer (`tools/mem_analyzer.js`)

```javascript
// Instrument WASM to log all memory accesses
// Visualize access patterns, detect cache-unfriendly patterns
```

---

## Test Suite Structure

```
tests/
├── correctness/
│   ├── fft.roundtrip.test.js      # ifft(fft(x)) = x
│   ├── fft.parseval.test.js       # Energy preservation
│   ├── fft.linearity.test.js      # Linearity property
│   ├── fft.shift.test.js          # Shift theorem
│   └── fft.reference.test.js      # Compare to fft.js
├── codelets/
│   ├── codelet.n2.test.js         # 2-point correctness
│   ├── codelet.n4.test.js         # 4-point correctness
│   ├── codelet.n8.test.js         # 8-point correctness
│   └── ...
├── performance/
│   ├── perf.regression.test.js    # Must not regress
│   ├── perf.scaling.test.js       # O(N log N) verification
│   └── perf.memory.test.js        # Memory bandwidth
└── integration/
    ├── real_fft.test.js           # Real FFT specific
    └── streaming.test.js          # Repeated FFT calls
```

---

## Migration Checklist

For each optimization, follow this checklist:

### Pre-Implementation

- [ ] Write correctness tests for affected code paths
- [ ] Establish baseline performance numbers
- [ ] Document expected improvement (with citation if applicable)

### Implementation

- [ ] Implement in isolated module
- [ ] Run correctness tests
- [ ] Run performance benchmarks
- [ ] Compare operation counts

### Post-Implementation

- [ ] All tests pass
- [ ] Performance improved (or explain why not)
- [ ] Code reviewed
- [ ] Documentation updated
- [ ] Benchmark results recorded

---

## Expected Performance Gains (Revised)

### High-Impact Optimizations (from FFTW Analysis)

| Optimization                 | Expected Gain    | Effort | Priority |
| ---------------------------- | ---------------- | ------ | -------- |
| **Twiddle-butterfly fusion** | **+25-40%**      | Medium | **A**    |
| **Fused real-FFT codelets**  | **+20-30% rfft** | Medium | **B**    |
| **DAG-based codelet gen**    | **+10-20%**      | High   | **C**    |
| **Depth-first recursion**    | **+15-25% N≥1K** | Medium | **D**    |
| Register-aware scheduling    | +5-10%           | Medium | E        |

### Original Optimizations

| Optimization      | Expected Gain   | Effort | Priority |
| ----------------- | --------------- | ------ | -------- |
| N=8 codelet       | +15% for N≤64   | Low    | 1        |
| N=16 codelet      | +10% for N≤256  | Low    | 2        |
| Radix-4 Stockham  | +20% overall    | Medium | 3        |
| Split-radix       | +25% overall    | High   | 4        |
| SIMD dual-complex | +30% for f32    | High   | 5        |
| Cache-oblivious   | +10% for N>1024 | Medium | 6        |

### Recommended Implementation Order

To close the 2x gap with fftw-js most efficiently:

1. **Twiddle-butterfly fusion** (Priority A) - Single biggest win, medium effort
2. **Basic codelets** (N=8, N=16) - Low-hanging fruit while building toward fusion
3. **Depth-first recursion** (Priority D) - Large-N improvement
4. **Fused rfft codelets** (Priority B) - Directly targets rfft performance
5. **Radix-4** - Compounds with above optimizations
6. **DAG codelet generator** (Priority C) - Long-term maintainability

**Target:** Match or exceed FFTW-js performance within 10%.

---

## References

1. FFTW Paper: ["The Design and Implementation of FFTW3"](https://www.fftw.org/fftw-paper-ieee.pdf) (Frigo & Johnson, 2005)
2. Genfft Compiler: ["A Fast Fourier Transform Compiler"](https://www.fftw.org/fftw-paper.pdf) (Frigo, PLDI 1999) - Won Most Influential Paper award
3. FFTW Adaptive Architecture: ["FFTW: An Adaptive Software Architecture"](https://www.fftw.org/fftw-paper-icassp.pdf) (Frigo & Johnson, ICASSP)
4. Implementing FFTs: ["Implementing FFTs in Practice"](https://www.csd.uwo.ca/~mmorenom/CS433-CS9624/Resources/Implementing_FFTs_in_Practice.pdf) (S.G. Johnson)
5. SIMD FFT: ["A Portable Short Vector Version of FFTW"](https://users.ece.cmu.edu/~franzf/papers/mathmod.pdf) (Franchetti et al.)
6. Generating Kernels: ["Generating Small FFT Kernels"](<https://eng.libretexts.org/Bookshelves/Electrical_Engineering/Signal_Processing_and_Modeling/Fast_Fourier_Transforms_(Burrus)/10:_Implementing_FFTs_in_Practice/10.06:_Generating_Small_FFT_Kernels>) (Engineering LibreTexts)
7. Split-Radix: "On Computing the Split-Radix FFT" (Sorensen et al., 1986)
8. Stockham: "High-Speed Convolution and Correlation" (Stockham, 1966)
9. fftw-js: [GitHub Repository](https://github.com/j-funk/fftw-js) - FFTW compiled to JS/WASM via Emscripten

---

## Next Steps

1. **Immediate:** Create `tests/correctness/` test suite
2. **Week 1:** Build codelet generator, generate N=8,16 codelets
3. **Week 2:** Implement radix-4 Stockham
4. **Week 3:** Benchmark and iterate
